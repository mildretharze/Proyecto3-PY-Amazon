Proyecto 3: Amazon Sales & Reviews

1. Importar los datos
En esta secciÃ³n cargamos los archivos CSV que contienen la informaciÃ³n deÂ productosÂ yÂ reseÃ±asÂ de Amazon.
Los datasets originales se llamanÂ amazon - amazon_product.csvÂ yÂ amazon - amazon_review.csv.
Para evitar problemas con los nombres (espacios y guiones), los renombramos con nombres mÃ¡s simples.


codigo:
```python
#Â ImportamosÂ laÂ librerÃ­aÂ necesaria
importÂ pandasÂ asÂ pdÂ Â #Â "pd"Â esÂ unÂ alias,Â loÂ usaremosÂ paraÂ llamarÂ aÂ pandas

#Â SubirÂ archivosÂ desdeÂ laÂ computadora
fromÂ google.colabÂ importÂ files

uploadedÂ =Â files.upload()Â Â #Â SeÂ abrirÃ¡Â unÂ cuadroÂ deÂ diÃ¡logoÂ paraÂ elegirÂ losÂ CSV

#Â RenombramosÂ directamenteÂ alÂ cargarlos
productosÂ =Â pd.read_csv("amazonÂ -Â amazon_product.csv")
resenasÂ =Â pd.read_csv("amazonÂ -Â amazon_review.csv")

#Â GuardamosÂ unaÂ copiaÂ conÂ nombresÂ mÃ¡sÂ simplesÂ paraÂ trabajarÂ sinÂ problemas
productos.to_csv("amazon_product.csv",Â index=False)
resenas.to_csv("amazon_review.csv",Â index=False)

#Â AhoraÂ reabrimosÂ usandoÂ losÂ nombresÂ limpios
productosÂ =Â pd.read_csv("amazon_product.csv")
resenasÂ =Â pd.read_csv("amazon_review.csv")

#Â VerificamosÂ cuÃ¡ntasÂ filasÂ yÂ columnasÂ tieneÂ cadaÂ dataset
print("Productos:",Â productos.shape)
print("ReseÃ±as:",Â resenas.shape)
```

ExploraciÃ³n de las columnas en cada DataFrame
En esta secciÃ³n verificamos las columnas disponibles en los dos DataFrames iniciales:
```python
productos: contiene la informaciÃ³n de los productos.
resenas: contiene la informaciÃ³n de las reseÃ±as de usuarios.
```

codigo:
```python
#Â VerÂ columnasÂ deÂ cadaÂ DataFrame
print("ColumnasÂ deÂ productos:")
print(productos.columns)

print("--------------------------------------------------")

print("ColumnasÂ deÂ resenas:")
print(resenas.columns)
```

2. Identificar y manejar valores nulos
En esta secciÃ³n:
Normalizamos los nombres de las columnas (todo en minÃºsculas, sin espacios).
Identificamos valores nulos en cada dataset.
Revisamos ejemplos de filas con nulos.
Calculamos cuÃ¡ntas filas tienen al menos un nulo.
Eliminamos columnas irrelevantes (img_link,Â product_link).
Rellenamos o estandarizamos datos:
about_productÂ â†’ reemplazado porÂ "sin informaciÃ³n"Â en caso de nulos.
rating_countÂ â†’ convertido a entero, limpiando nulos y valores no vÃ¡lidos.
Guardamos los archivos limpios para anÃ¡lisis posterior.

codigo:
```python
#Â 0)Â NormalizarÂ nombresÂ deÂ columnasÂ paraÂ evitarÂ problemasÂ deÂ mayÃºsculas/espacios
productos.columnsÂ =Â productos.columns.str.strip().str.lower().str.replace('Â ',Â '_',Â regex=False)
resenas.columnsÂ Â =Â resenas.columns.str.strip().str.lower().str.replace('Â ',Â '_',Â regex=False)

#Â 1)Â ResumenÂ deÂ nulos:Â conteoÂ yÂ porcentaje
defÂ null_summary(df,Â df_name):
Â Â Â Â totalÂ =Â len(df)
Â Â Â Â nulosÂ =Â df.isnull().sum()
Â Â Â Â pctÂ =Â (nulosÂ /Â totalÂ *Â 100).round(2)
Â Â Â Â summaryÂ =Â pd.DataFrame({
Â Â Â Â Â Â Â Â 'column':Â nulos.index,
Â Â Â Â Â Â Â Â 'n_null':Â nulos.values,
Â Â Â Â Â Â Â Â 'pct_null':Â pct.values
Â Â Â Â })
Â Â Â Â summaryÂ =Â summary.sort_values(by='n_null',Â ascending=False).reset_index(drop=True)
Â Â Â Â print(f"\n---Â ResumenÂ nulos:Â {df_name}Â (totalÂ filas:Â {total})Â ---")
Â Â Â Â display(summary)
Â Â Â Â returnÂ summary

summary_prodÂ =Â null_summary(productos,Â "productos")
summary_revÂ Â =Â null_summary(resenas,Â "resenas")

#Â 2)Â MostrarÂ ejemplosÂ (hastaÂ 5)Â deÂ filasÂ dondeÂ cadaÂ columnaÂ tengaÂ nulosÂ (porÂ dataset)
defÂ show_null_examples(df,Â summary,Â df_name,Â n=5):
Â Â Â Â cols_with_nullsÂ =Â summary.loc[summary['n_null']Â >Â 0,Â 'column'].tolist()
Â Â Â Â ifÂ notÂ cols_with_nulls:
Â Â Â Â Â Â Â Â print(f"\nNoÂ hayÂ columnasÂ conÂ nulosÂ enÂ {df_name}.")
Â Â Â Â Â Â Â Â return
Â Â Â Â forÂ colÂ inÂ cols_with_nulls:
Â Â Â Â Â Â Â Â print(f"\n{df_name}Â -Â EjemplosÂ deÂ filasÂ conÂ {col}Â nuloÂ (hastaÂ {n}):")
Â Â Â Â Â Â Â Â display(df[df[col].isnull()].head(n))

show_null_examples(productos,Â summary_prod,Â "productos")
show_null_examples(resenas,Â summary_rev,Â "resenas")

#Â 3)Â FilasÂ queÂ tienenÂ alÂ menosÂ 1Â nuloÂ (cantidadÂ yÂ %),Â yÂ mostrarÂ ejemplo
forÂ df,Â nameÂ inÂ [(productos,Â "productos"),Â (resenas,Â "resenas")]:
Â Â Â Â filas_con_algun_nuloÂ =Â df.isnull().any(axis=1).sum()
Â Â Â Â pct_filasÂ =Â (filas_con_algun_nuloÂ /Â len(df)Â *Â 100).round(2)
Â Â Â Â print(f"\n{name}:Â {filas_con_algun_nulo}Â filasÂ ({pct_filas}%)Â conÂ alÂ menosÂ 1Â valorÂ nulo.")
Â Â Â Â display(df[df.isnull().any(axis=1)].head(5))

#Â 4)Â GuardarÂ resumenÂ aÂ CSV
summary_prod.to_csv('null_summary_productos.csv',Â index=False)
summary_rev.to_csv('null_summary_resenas.csv',Â index=False)
print("\nResÃºmenesÂ guardados:Â null_summary_productos.csv,Â null_summary_resenas.csv")
```

codigo:
```python
#Â --Â LIMPIEZAÂ DEÂ DATOSÂ AMAZONÂ --
importÂ pandasÂ asÂ pd

#Â 1)Â MOSTRARÂ ESTADOÂ INICIAL
print("===Â ESTADOÂ INICIALÂ ===")
print(f"Productos:Â {productos.shape[0]}Â filas,Â {productos.shape[1]}Â columnas")
print(f"ReseÃ±as:Â {resenas.shape[0]}Â filas,Â {resenas.shape[1]}Â columnas")

print("\nğŸ”Â NulosÂ inicialesÂ -Â Productos:")
print(productos.isnull().sum())
print("\nğŸ”Â NulosÂ inicialesÂ -Â ReseÃ±as:")
print(resenas.isnull().sum())

#Â 2)Â LIMPIEZAÂ DEÂ DATOS
print("\n===Â PROCESOÂ DEÂ LIMPIEZAÂ ===")

#Â A.Â Productos:Â RellenarÂ nulosÂ enÂ about_product
productos['about_product']Â =Â productos['about_product'].fillna("sinÂ informaciÃ³n")
print("âœ…Â about_product:Â nulosÂ remplazadosÂ porÂ 'sinÂ informaciÃ³n'")

#Â B.Â ReseÃ±as:Â EliminarÂ columnasÂ irrelevantes
columnas_eliminadasÂ =Â []
forÂ columnaÂ inÂ ['img_link',Â 'product_link']:
Â Â Â Â ifÂ columnaÂ inÂ resenas.columns:
Â Â Â Â Â Â Â Â resenasÂ =Â resenas.drop(columns=columna)
Â Â Â Â Â Â Â Â columnas_eliminadas.append(columna)

ifÂ columnas_eliminadas:
Â Â Â Â print(f"âœ…Â ColumnasÂ eliminadas:Â {',Â '.join(columnas_eliminadas)}")
else:
Â Â Â Â print("â„¹ï¸Â NoÂ seÂ eliminaronÂ columnas")

#Â C.Â ReseÃ±as:Â LimpiarÂ yÂ convertirÂ rating_count
ifÂ 'rating_count'Â inÂ resenas.columns:
Â Â Â Â #Â ContarÂ nulosÂ antesÂ deÂ limpiar
Â Â Â Â nulos_antesÂ =Â resenas['rating_count'].isnull().sum()

Â Â Â Â #Â LimpiezaÂ pasoÂ aÂ paso
Â Â Â Â resenas['rating_count']Â =Â (
Â Â Â Â Â Â Â Â resenas['rating_count']
Â Â Â Â Â Â Â Â .astype(str)Â Â #Â ConvertirÂ todoÂ aÂ texto
Â Â Â Â Â Â Â Â .str.replace(',',Â '')Â Â #Â QuitarÂ comasÂ deÂ miles
Â Â Â Â Â Â Â Â .str.strip()Â Â #Â QuitarÂ espacios
Â Â Â Â Â Â Â Â .replace('nan',Â '0')Â Â #Â RemplazarÂ textoÂ 'nan'Â porÂ '0'
Â Â Â Â Â Â Â Â .replace('',Â '0')Â Â #Â RemplazarÂ cadenasÂ vacÃ­asÂ porÂ '0'
Â Â Â Â )

Â Â Â Â #Â ConvertirÂ aÂ numÃ©ricoÂ (losÂ erroresÂ seÂ conviertenÂ enÂ NaN)
Â Â Â Â resenas['rating_count']Â =Â pd.to_numeric(resenas['rating_count'],Â errors='coerce')

Â Â Â Â #Â RellenarÂ cualquierÂ NaNÂ restanteÂ conÂ 0Â yÂ convertirÂ aÂ entero
Â Â Â Â resenas['rating_count']Â =Â resenas['rating_count'].fillna(0).astype(int)

Â Â Â Â print(f"âœ…Â rating_count:Â {nulos_antes}Â nulosÂ convertidosÂ aÂ 0Â yÂ estandarizados")

#Â 3)Â VERIFICACIÃ“NÂ FINAL
print("\n===Â VERIFICACIÃ“NÂ FINALÂ ===")
print(f"Productos:Â {productos.shape[0]}Â filas,Â {productos.shape[1]}Â columnas")
print(f"ReseÃ±as:Â {resenas.shape[0]}Â filas,Â {resenas.shape[1]}Â columnas")

print("\nğŸ”Â NulosÂ despuÃ©sÂ deÂ limpiezaÂ -Â Productos:")
print(productos.isnull().sum())
print("\nğŸ”Â NulosÂ despuÃ©sÂ deÂ limpiezaÂ -Â ReseÃ±as:")
print(resenas.isnull().sum())

#Â 4)Â MUESTRASÂ DEÂ VALIDACIÃ“N
print("\n===Â VALIDACIÃ“NÂ DEÂ CAMBIOSÂ ===")

#Â MostrarÂ productosÂ queÂ tenÃ­anÂ nulosÂ yÂ ahoraÂ tienenÂ "sinÂ informaciÃ³n"
productos_sin_infoÂ =Â productos[productos['about_product']Â ==Â "sinÂ informaciÃ³n"]
print(f"ğŸ“‹Â ProductosÂ conÂ 'sinÂ informaciÃ³n':Â {len(productos_sin_info)}")

ifÂ len(productos_sin_info)Â >Â 0:
Â Â Â Â print("MuestraÂ deÂ productosÂ conÂ descripciÃ³nÂ remplazada:")
Â Â Â Â display(productos_sin_info[['product_id',Â 'product_name',Â 'about_product']].head(3))

#Â MostrarÂ estadÃ­sticasÂ deÂ rating_count
ifÂ 'rating_count'Â inÂ resenas.columns:
Â Â Â Â print(f"\nğŸ“ŠÂ EstadÃ­sticasÂ deÂ rating_count:")
Â Â Â Â print(f"Â Â Â MÃ­nimo:Â {resenas['rating_count'].min()}")
Â Â Â Â print(f"Â Â Â MÃ¡ximo:Â {resenas['rating_count'].max()}")
Â Â Â Â print(f"Â Â Â Promedio:Â {resenas['rating_count'].mean():.2f}")
Â Â Â Â print(f"Â Â Â Ceros:Â {(resenas['rating_count']Â ==Â 0).sum()}")

#Â 5)Â GUARDARÂ DATOSÂ LIMPIOSÂ (OPCIONAL)
productos.to_csv("amazon_productos_limpio.csv",Â index=False)
resenas.to_csv("amazon_resenas_limpio.csv",Â index=False)
print("\nğŸ’¾Â ArchivosÂ guardados:Â amazon_productos_limpio.csv,Â amazon_resenas_limpio.csv")

print("\nğŸ‰Â Â¡LimpiezaÂ completadaÂ exitosamente!")
```

Resultados despuÃ©s de la limpieza:
about_product: sin nulos (rellenados conÂ "sin informaciÃ³n").
img_link,Â product_link: eliminadas por irrelevantes.
rating_count: transformado a entero, nulos y valores inconsistentes convertidos aÂ 0.
ğŸ“ŠÂ VerificaciÃ³n final:
Productos: 1351 filas, 19 columnas â†’ 0 nulos.
ReseÃ±as: 1194 filas, 16 columnas â†’ solo queda 1 nulo enÂ rating_original_numeric.
ğŸ’¾ Se guardaron los datasets limpios:
amazon_productos_limpio.csv
amazon_resenas_limpio.csv
ğŸ‰ Limpieza completada exitosamente.

3. Identificar y manejar valores duplicados
En esta secciÃ³n identificamos y gestionamos los valores duplicados en las tablasÂ productosÂ yÂ reseÃ±as, aplicando criterios claros para su depuraciÃ³n.

AnÃ¡lisis de duplicados
ğŸ“¦ Productos
Duplicados completos:Â 106
product_idÂ duplicados:Â 118
Se detectaron mÃºltiplesÂ product_idÂ duplicados, como por ejemplo:

codigo:
```python
#Â =============================================================================
#Â ANÃLISISÂ DEÂ VALORESÂ DUPLICADOS
#Â =============================================================================

print("ğŸ”Â INICIANDOÂ BÃšSQUEDAÂ DEÂ DUPLICADOS")
print("="Â *Â 50)

#Â 1.Â DUPLICADOSÂ ENÂ TABLAÂ PRODUCTOS
print("\nğŸ“¦Â PRODUCTOSÂ -Â AnÃ¡lisisÂ deÂ duplicados:")
print("-"Â *Â 40)

#Â A)Â DuplicadosÂ completosÂ (todasÂ lasÂ columnasÂ iguales)
duplicados_completos_prodÂ =Â productos.duplicated().sum()
print(f"DuplicadosÂ completos:Â {duplicados_completos_prod}")

#Â B)Â DuplicadosÂ enÂ columnasÂ claveÂ (product_idÂ deberÃ­aÂ serÂ Ãºnico)
duplicados_id_prodÂ =Â productos['product_id'].duplicated().sum()
print(f"DuplicadosÂ enÂ product_id:Â {duplicados_id_prod}")

#Â C)Â MostrarÂ losÂ duplicadosÂ deÂ product_idÂ siÂ existen
ifÂ duplicados_id_prodÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â PRODUCTOSÂ DUPLICADOSÂ (product_id):")
Â Â Â Â ids_duplicadosÂ =Â productos[productos['product_id'].duplicated(keep=False)]['product_id'].unique()
Â Â Â Â print(f"IDsÂ duplicados:Â {ids_duplicados}")

Â Â Â Â #Â MostrarÂ todasÂ lasÂ filasÂ conÂ IDsÂ duplicados
Â Â Â Â productos_duplicadosÂ =Â productos[productos['product_id'].isin(ids_duplicados)]
Â Â Â Â display(productos_duplicados.sort_values('product_id'))
else:
Â Â Â Â print("âœ…Â NoÂ hayÂ product_idÂ duplicados")

#Â 2.Â DUPLICADOSÂ ENÂ TABLAÂ RESEÃ‘AS
print("\nâ­Â RESEÃ‘ASÂ -Â AnÃ¡lisisÂ deÂ duplicados:")
print("-"Â *Â 40)

#Â A)Â DuplicadosÂ completos
duplicados_completos_revÂ =Â resenas.duplicated().sum()
print(f"DuplicadosÂ completos:Â {duplicados_completos_rev}")

#Â B)Â DuplicadosÂ enÂ columnasÂ clave
duplicados_review_idÂ =Â resenas['review_id'].duplicated().sum()
print(f"DuplicadosÂ enÂ review_id:Â {duplicados_review_id}")

duplicados_user_productÂ =Â resenas.duplicated(subset=['user_id',Â 'product_id']).sum()
print(f"UsuariosÂ conÂ mÃºltiplesÂ reseÃ±asÂ delÂ mismoÂ producto:Â {duplicados_user_product}")

#Â C)Â MostrarÂ duplicadosÂ siÂ existen
ifÂ duplicados_completos_revÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â RESEÃ‘ASÂ DUPLICADASÂ COMPLETAS:")
Â Â Â Â reseÃ±as_duplicadasÂ =Â resenas[resenas.duplicated(keep=False)]
Â Â Â Â display(reseÃ±as_duplicadas.sort_values('review_id'))

ifÂ duplicados_review_idÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â REVIEW_IDÂ DUPLICADOS:")
Â Â Â Â reviews_duplicadosÂ =Â resenas[resenas['review_id'].duplicated(keep=False)]
Â Â Â Â display(reviews_duplicados.sort_values('review_id'))

#Â 3.Â ANÃLISISÂ DEÂ DUPLICADOSÂ PARCIALES
print("\nğŸ”Â ANÃLISISÂ DEÂ DUPLICADOSÂ PARCIALES:")
print("-"Â *Â 40)

#Â A)Â UsuariosÂ queÂ mÃ¡sÂ reseÃ±an
usuarios_activosÂ =Â resenas['user_id'].value_counts().head(5)
print("ğŸ‘¥Â TopÂ 5Â usuariosÂ mÃ¡sÂ activos:")
print(usuarios_activos)

#Â B)Â ProductosÂ mÃ¡sÂ reseÃ±ados
productos_popularesÂ =Â resenas['product_id'].value_counts().head(5)
print("\nğŸ†Â TopÂ 5Â productosÂ mÃ¡sÂ reseÃ±ados:")
print(productos_populares)

#Â 4.Â RESUMENÂ FINAL
print("\n"Â +Â "="Â *Â 50)
print("ğŸ“ŠÂ RESUMENÂ DEÂ DUPLICADOS:")
print("="Â *Â 50)

print(f"ğŸ“¦Â PRODUCTOS:")
print(f"Â Â Â -Â DuplicadosÂ completos:Â {duplicados_completos_prod}")
print(f"Â Â Â -Â product_idÂ duplicados:Â {duplicados_id_prod}")

print(f"\nâ­Â RESEÃ‘AS:")
print(f"Â Â Â -Â DuplicadosÂ completos:Â {duplicados_completos_rev}")
print(f"Â Â Â -Â review_idÂ duplicados:Â {duplicados_review_id}")
print(f"Â Â Â -Â MÃºltiplesÂ reseÃ±asÂ porÂ usuario-producto:Â {duplicados_user_product}")

#Â 5.Â RECOMENDACIONES
print("\nğŸ’¡Â RECOMENDACIONES:")
print("-"Â *Â 30)

ifÂ duplicados_completos_prodÂ >Â 0:
Â Â Â Â print("âŒÂ EliminarÂ duplicadosÂ completosÂ deÂ productos")

ifÂ duplicados_id_prodÂ >Â 0:
Â Â Â Â print("âŒÂ InvestigarÂ product_idÂ duplicadosÂ (deberÃ­anÂ serÂ Ãºnicos)")

ifÂ duplicados_completos_revÂ >Â 0:
Â Â Â Â print("âŒÂ EliminarÂ reseÃ±asÂ duplicadasÂ completas")

ifÂ duplicados_review_idÂ >Â 0:
Â Â Â Â print("âŒÂ InvestigarÂ review_idÂ duplicadosÂ (deberÃ­anÂ serÂ Ãºnicos)")

ifÂ duplicados_user_productÂ >Â 0:
Â Â Â Â print("âš ï¸Â Â UsuariosÂ conÂ mÃºltiplesÂ reseÃ±asÂ delÂ mismoÂ productoÂ -Â puedeÂ serÂ vÃ¡lido")

print("\nâœ…Â AnÃ¡lisisÂ deÂ duplicadosÂ completado")
```

Limpieza de valores duplicados
Una vez identificados los duplicados, se aplicaron acciones de limpieza segÃºn criterio:

ğŸ“¦ Productos
EliminaciÃ³n de duplicados enÂ product_id.
Se conservÃ³Â solo la primera ocurrenciaÂ de cada producto.
Resultado:
Duplicados eliminados:Â 118
Filas finales:Â 1,351
Sin duplicados restantes enÂ product_id.

â­ ReseÃ±as
EliminaciÃ³n de duplicados enÂ review_id.
Se conservÃ³Â solo la primera ocurrenciaÂ de cada reseÃ±a.
Resultado:
Duplicados eliminados:Â 271
Filas finales:Â 1,194
Sin duplicados restantes enÂ review_id.

âœ… VerificaciÃ³n final
Ambas tablas quedaron sin duplicados en sus claves Ãºnicas (product_idÂ yÂ review_id).
Se verificÃ³ que los datos conservados mantienen la integridad del anÃ¡lisis.

ğŸ’¾ Archivos exportados
Los datos limpios fueron guardados como:
```python
productos_sin_duplicados.csv
resenas_sin_duplicados.csv
```
Esto permite reutilizar los datasets ya depurados en los siguientes pasos.

ğŸ“Š Resumen ejecutivo
Total de filas eliminadas:Â 389
Total de filas finales:Â 2,545
Porcentaje de datos conservados:Â 86.7%
ğŸ¯Â La limpieza de duplicados se completÃ³ con Ã©xito.

codigo:
```python
#Â =============================================================================
#Â PASOÂ 1:Â ELIMINARÂ DUPLICADOSÂ SEGÃšNÂ CRITERIOÂ ESPECÃFICO
#Â =============================================================================

print("ğŸ§¹Â ELIMINANDOÂ DUPLICADOSÂ PORÂ IDÂ ÃšNICOÂ -Â PRIMERAÂ OCURRENCIA")
print("="Â *Â 60)

#Â GuardarÂ elÂ estadoÂ originalÂ paraÂ comparar
print("ğŸ“ŠÂ ESTADOÂ INICIAL:")
print(f"Â Â Â Productos:Â {productos.shape[0]}Â filas,Â {productos.shape[1]}Â columnas")
print(f"Â Â Â ReseÃ±as:Â {resenas.shape[0]}Â filas,Â {resenas.shape[1]}Â columnas")

#Â -----------------------------------------------------------------------------
#Â A.Â ELIMINARÂ DUPLICADOSÂ ENÂ PRODUCTOSÂ (porÂ product_id)
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*50)
print("ğŸ“¦Â PROCESANDOÂ PRODUCTOSÂ -Â product_id")
print("="*50)

#Â ContarÂ duplicadosÂ antesÂ deÂ eliminar
duplicados_prod_antesÂ =Â productos['product_id'].duplicated().sum()
print(f"DuplicadosÂ encontradosÂ enÂ product_id:Â {duplicados_prod_antes}")

ifÂ duplicados_prod_antesÂ >Â 0:
Â Â Â Â #Â MostrarÂ algunosÂ ejemplosÂ deÂ IDsÂ duplicados
Â Â Â Â ids_duplicados_prodÂ =Â productos[productos['product_id'].duplicated(keep=False)]['product_id'].unique()[:5]
Â Â Â Â print(f"EjemplosÂ deÂ product_idÂ duplicados:Â {ids_duplicados_prod}")

Â Â Â Â #Â MostrarÂ cÃ³moÂ seÂ venÂ losÂ duplicadosÂ paraÂ unÂ IDÂ especÃ­fico
Â Â Â Â ejemplo_idÂ =Â ids_duplicados_prod[0]Â ifÂ len(ids_duplicados_prod)Â >Â 0Â elseÂ None
Â Â Â Â ifÂ ejemplo_id:
Â Â Â Â Â Â Â Â print(f"\nğŸ”Â EjemploÂ deÂ duplicadosÂ paraÂ product_idÂ '{ejemplo_id}':")
Â Â Â Â Â Â Â Â duplicados_ejemploÂ =Â productos[productos['product_id']Â ==Â ejemplo_id]
Â Â Â Â Â Â Â Â display(duplicados_ejemplo)

Â Â Â Â #Â ELIMINARÂ DUPLICADOSÂ (mantenerÂ laÂ primeraÂ ocurrencia)
Â Â Â Â productosÂ =Â productos.drop_duplicates(subset='product_id',Â keep='first')
Â Â Â Â print("âœ…Â DuplicadosÂ eliminadosÂ -Â seÂ mantuvoÂ laÂ primeraÂ ocurrencia")
else:
Â Â Â Â print("âœ…Â NoÂ hayÂ duplicadosÂ enÂ product_id")

#Â VerificarÂ resultado
duplicados_prod_despuesÂ =Â productos['product_id'].duplicated().sum()
print(f"DuplicadosÂ restantesÂ enÂ product_id:Â {duplicados_prod_despues}")

#Â -----------------------------------------------------------------------------
#Â B.Â ELIMINARÂ DUPLICADOSÂ ENÂ RESEÃ‘ASÂ (porÂ review_id)
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*50)
print("â­Â PROCESANDOÂ RESEÃ‘ASÂ -Â review_id")
print("="*50)

#Â ContarÂ duplicadosÂ antesÂ deÂ eliminar
duplicados_rev_antesÂ =Â resenas['review_id'].duplicated().sum()
print(f"DuplicadosÂ encontradosÂ enÂ review_id:Â {duplicados_rev_antes}")

ifÂ duplicados_rev_antesÂ >Â 0:
Â Â Â Â #Â MostrarÂ algunosÂ ejemplosÂ deÂ IDsÂ duplicados
Â Â Â Â ids_duplicados_revÂ =Â resenas[resenas['review_id'].duplicated(keep=False)]['review_id'].unique()[:5]
Â Â Â Â print(f"EjemplosÂ deÂ review_idÂ duplicados:Â {ids_duplicados_rev}")

Â Â Â Â #Â MostrarÂ cÃ³moÂ seÂ venÂ losÂ duplicadosÂ paraÂ unÂ IDÂ especÃ­fico
Â Â Â Â ejemplo_id_revÂ =Â ids_duplicados_rev[0]Â ifÂ len(ids_duplicados_rev)Â >Â 0Â elseÂ None
Â Â Â Â ifÂ ejemplo_id_rev:
Â Â Â Â Â Â Â Â print(f"\nğŸ”Â EjemploÂ deÂ duplicadosÂ paraÂ review_idÂ '{ejemplo_id_rev}':")
Â Â Â Â Â Â Â Â duplicados_ejemplo_revÂ =Â resenas[resenas['review_id']Â ==Â ejemplo_id_rev]
Â Â Â Â Â Â Â Â display(duplicados_ejemplo_rev)

Â Â Â Â #Â ELIMINARÂ DUPLICADOSÂ (mantenerÂ laÂ primeraÂ ocurrencia)
Â Â Â Â resenasÂ =Â resenas.drop_duplicates(subset='review_id',Â keep='first')
Â Â Â Â print("âœ…Â DuplicadosÂ eliminadosÂ -Â seÂ mantuvoÂ laÂ primeraÂ ocurrencia")
else:
Â Â Â Â print("âœ…Â NoÂ hayÂ duplicadosÂ enÂ review_id")

#Â VerificarÂ resultado
duplicados_rev_despuesÂ =Â resenas['review_id'].duplicated().sum()
print(f"DuplicadosÂ restantesÂ enÂ review_id:Â {duplicados_rev_despues}")

#Â =============================================================================
#Â PASOÂ 2:Â VERIFICACIÃ“NÂ FINAL
#Â =============================================================================
print("\n"Â +Â "="*60)
print("âœ…Â VERIFICACIÃ“NÂ FINAL")
print("="*60)

#Â MostrarÂ resultadosÂ finales
filas_finales_prodÂ =Â productos.shape[0]
filas_finales_revÂ =Â resenas.shape[0]

print(f"ğŸ“¦Â PRODUCTOSÂ FINALES:Â {filas_finales_prod}Â filas")
print(f"Â Â Â -Â DuplicadosÂ eliminados:Â {duplicados_prod_antes}")
print(f"Â Â Â -Â DuplicadosÂ restantes:Â {duplicados_prod_despues}")

print(f"\nâ­Â RESEÃ‘ASÂ FINALES:Â {filas_finales_rev}Â filas")
print(f"Â Â Â -Â DuplicadosÂ eliminados:Â {duplicados_rev_antes}")
print(f"Â Â Â -Â DuplicadosÂ restantes:Â {duplicados_rev_despues}")

#Â VerificarÂ queÂ noÂ quedanÂ duplicadosÂ enÂ lasÂ clavesÂ Ãºnicas
ifÂ duplicados_prod_despuesÂ ==Â 0Â andÂ duplicados_rev_despuesÂ ==Â 0:
Â Â Â Â print("\nğŸ‰Â Â¡Ã‰XITO!Â NoÂ hayÂ duplicadosÂ restantesÂ enÂ lasÂ clavesÂ Ãºnicas")
else:
Â Â Â Â print("\nâš ï¸Â Â AÃºnÂ quedanÂ duplicados.å¯èƒ½éœ€è¦Â revisiÃ³nÂ manual")

#Â =============================================================================
#Â PASOÂ 3:Â GUARDARÂ RESULTADOS
#Â =============================================================================
print("\n"Â +Â "="*60)
print("ğŸ’¾Â GUARDANDOÂ RESULTADOS")
print("="*60)

#Â GuardarÂ losÂ datosÂ limpios
productos.to_csv("productos_sin_duplicados.csv",Â index=False)
resenas.to_csv("resenas_sin_duplicados.csv",Â index=False)

print("âœ…Â ArchivosÂ guardados:")
print("Â Â Â -Â productos_sin_duplicados.csv")
print("Â Â Â -Â resenas_sin_duplicados.csv")

print("\nğŸ”Â ParaÂ verificar,Â puedesÂ cargarÂ losÂ archivosÂ guardados:")
print("Â Â Â productos_verificarÂ =Â pd.read_csv('productos_sin_duplicados.csv')")
print("Â Â Â resenas_verificarÂ =Â pd.read_csv('resenas_sin_duplicados.csv')")

#Â =============================================================================
#Â PASOÂ 4:Â RESUMENÂ EJECUTIVO
#Â =============================================================================
print("\n"Â +Â "="*60)
print("ğŸ“ŠÂ RESUMENÂ EJECUTIVO")
print("="*60)

total_eliminadoÂ =Â duplicados_prod_antesÂ +Â duplicados_rev_antes
total_finalÂ =Â filas_finales_prodÂ +Â filas_finales_rev

print(f"ğŸ“ˆÂ TotalÂ deÂ filasÂ eliminadas:Â {total_eliminado}")
print(f"ğŸ“ˆÂ TotalÂ deÂ filasÂ finales:Â {total_final}")
print(f"ğŸ“ˆÂ PorcentajeÂ deÂ datosÂ conservados:Â {(total_final/(total_finalÂ +Â total_eliminado))*100:.1f}%")

print("\nÂ¡ProcesoÂ completado!Â ğŸ¯")
```

codigo:
```python
#Â =============================================================================
#Â ANÃLISISÂ DEÂ VALORESÂ DUPLICADOS
#Â =============================================================================

print("ğŸ”Â INICIANDOÂ BÃšSQUEDAÂ DEÂ DUPLICADOS")
print("="Â *Â 50)

#Â 1.Â DUPLICADOSÂ ENÂ TABLAÂ PRODUCTOS
print("\nğŸ“¦Â PRODUCTOSÂ -Â AnÃ¡lisisÂ deÂ duplicados:")
print("-"Â *Â 40)

#Â A)Â DuplicadosÂ completosÂ (todasÂ lasÂ columnasÂ iguales)
duplicados_completos_prodÂ =Â productos.duplicated().sum()
print(f"DuplicadosÂ completos:Â {duplicados_completos_prod}")

#Â B)Â DuplicadosÂ enÂ columnasÂ claveÂ (product_idÂ deberÃ­aÂ serÂ Ãºnico)
duplicados_id_prodÂ =Â productos['product_id'].duplicated().sum()
print(f"DuplicadosÂ enÂ product_id:Â {duplicados_id_prod}")

#Â C)Â MostrarÂ losÂ duplicadosÂ deÂ product_idÂ siÂ existen
ifÂ duplicados_id_prodÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â PRODUCTOSÂ DUPLICADOSÂ (product_id):")
Â Â Â Â ids_duplicadosÂ =Â productos[productos['product_id'].duplicated(keep=False)]['product_id'].unique()
Â Â Â Â print(f"IDsÂ duplicados:Â {ids_duplicados}")

Â Â Â Â #Â MostrarÂ todasÂ lasÂ filasÂ conÂ IDsÂ duplicados
Â Â Â Â productos_duplicadosÂ =Â productos[productos['product_id'].isin(ids_duplicados)]
Â Â Â Â display(productos_duplicados.sort_values('product_id'))
else:
Â Â Â Â print("âœ…Â NoÂ hayÂ product_idÂ duplicados")

#Â 2.Â DUPLICADOSÂ ENÂ TABLAÂ RESEÃ‘AS
print("\nâ­Â RESEÃ‘ASÂ -Â AnÃ¡lisisÂ deÂ duplicados:")
print("-"Â *Â 40)

#Â A)Â DuplicadosÂ completos
duplicados_completos_revÂ =Â resenas.duplicated().sum()
print(f"DuplicadosÂ completos:Â {duplicados_completos_rev}")

#Â B)Â DuplicadosÂ enÂ columnasÂ clave
duplicados_review_idÂ =Â resenas['review_id'].duplicated().sum()
print(f"DuplicadosÂ enÂ review_id:Â {duplicados_review_id}")

duplicados_user_productÂ =Â resenas.duplicated(subset=['user_id',Â 'product_id']).sum()
print(f"UsuariosÂ conÂ mÃºltiplesÂ reseÃ±asÂ delÂ mismoÂ producto:Â {duplicados_user_product}")

#Â C)Â MostrarÂ duplicadosÂ siÂ existen
ifÂ duplicados_completos_revÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â RESEÃ‘ASÂ DUPLICADASÂ COMPLETAS:")
Â Â Â Â reseÃ±as_duplicadasÂ =Â resenas[resenas.duplicated(keep=False)]
Â Â Â Â display(reseÃ±as_duplicadas.sort_values('review_id'))

ifÂ duplicados_review_idÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â REVIEW_IDÂ DUPLICADOS:")
Â Â Â Â reviews_duplicadosÂ =Â resenas[resenas['review_id'].duplicated(keep=False)]
Â Â Â Â display(reviews_duplicados.sort_values('review_id'))

#Â 3.Â ANÃLISISÂ DEÂ DUPLICADOSÂ PARCIALES
print("\nğŸ”Â ANÃLISISÂ DEÂ DUPLICADOSÂ PARCIALES:")
print("-"Â *Â 40)

#Â A)Â UsuariosÂ queÂ mÃ¡sÂ reseÃ±an
usuarios_activosÂ =Â resenas['user_id'].value_counts().head(5)
print("ğŸ‘¥Â TopÂ 5Â usuariosÂ mÃ¡sÂ activos:")
print(usuarios_activos)

#Â B)Â ProductosÂ mÃ¡sÂ reseÃ±ados
productos_popularesÂ =Â resenas['product_id'].value_counts().head(5)
print("\nğŸ†Â TopÂ 5Â productosÂ mÃ¡sÂ reseÃ±ados:")
print(productos_populares)

#Â 4.Â RESUMENÂ FINAL
print("\n"Â +Â "="Â *Â 50)
print("ğŸ“ŠÂ RESUMENÂ DEÂ DUPLICADOS:")
print("="Â *Â 50)

print(f"ğŸ“¦Â PRODUCTOS:")
print(f"Â Â Â -Â DuplicadosÂ completos:Â {duplicados_completos_prod}")
print(f"Â Â Â -Â product_idÂ duplicados:Â {duplicados_id_prod}")

print(f"\nâ­Â RESEÃ‘AS:")
print(f"Â Â Â -Â DuplicadosÂ completos:Â {duplicados_completos_rev}")
print(f"Â Â Â -Â review_idÂ duplicados:Â {duplicados_review_id}")
print(f"Â Â Â -Â MÃºltiplesÂ reseÃ±asÂ porÂ usuario-producto:Â {duplicados_user_product}")

#Â 5.Â RECOMENDACIONES
print("\nğŸ’¡Â RECOMENDACIONES:")
print("-"Â *Â 30)

ifÂ duplicados_completos_prodÂ >Â 0:
Â Â Â Â print("âŒÂ EliminarÂ duplicadosÂ completosÂ deÂ productos")

ifÂ duplicados_id_prodÂ >Â 0:
Â Â Â Â print("âŒÂ InvestigarÂ product_idÂ duplicadosÂ (deberÃ­anÂ serÂ Ãºnicos)")

ifÂ duplicados_completos_revÂ >Â 0:
Â Â Â Â print("âŒÂ EliminarÂ reseÃ±asÂ duplicadasÂ completas")

ifÂ duplicados_review_idÂ >Â 0:
Â Â Â Â print("âŒÂ InvestigarÂ review_idÂ duplicadosÂ (deberÃ­anÂ serÂ Ãºnicos)")

ifÂ duplicados_user_productÂ >Â 0:
Â Â Â Â print("âš ï¸Â Â UsuariosÂ conÂ mÃºltiplesÂ reseÃ±asÂ delÂ mismoÂ productoÂ -Â puedeÂ serÂ vÃ¡lido")

print("\nâœ…Â AnÃ¡lisisÂ deÂ duplicadosÂ completado")
```

4. AnÃ¡lisis completo del formato
En esta secciÃ³n se realizÃ³ una revisiÃ³n exhaustiva de losÂ tipos de datos y formatosÂ en cada columna de los datasetsÂ productosÂ yÂ reseÃ±as.
El objetivo fueÂ detectar inconsistenciasÂ y preparar las variables para un anÃ¡lisis posterior.

ğŸ“¦ Productos
Todas las columnas estaban inicialmente en formatoÂ objectÂ (texto), incluyendo precios y porcentajes.
Variables comoÂ discounted_price,Â actual_priceÂ yÂ discount_percentageÂ contenÃ­anÂ sÃ­mbolos no numÃ©ricosÂ (â‚¹, %, comas de miles).
Se detectÃ³ la necesidad de conversiÃ³n de estas columnas aÂ valores numÃ©ricos (float).
La columnaÂ about_productÂ mostrÃ³ gran longitud de texto, Ãºtil para futuros anÃ¡lisis deÂ procesamiento de lenguaje natural (NLP).

â­ ReseÃ±as
La mayorÃ­a de las columnas son de tipoÂ object.
La variableÂ ratingÂ estaba almacenada como texto, aunque corresponde a valores numÃ©ricos.
rating_countÂ ya estaba correctamente en formato numÃ©rico (int64).
Columnas de texto comoÂ review_contentÂ yÂ review_titleÂ mostraron alta longitud de caracteres, indicando descripciones ricas en informaciÃ³n.

ğŸš¨ Problemas detectados
Productos:
discounted_priceÂ â†’ contieneÂ â‚¹Â y comas.
actual_priceÂ â†’ contieneÂ â‚¹Â y comas.
discount_percentageÂ â†’ contieneÂ %.
ReseÃ±as:
ratingÂ â†’ deberÃ­a convertirse a decimal.

ğŸ¯ ConversiÃ³n aplicada (Paso 1)
Se realizÃ³ la conversiÃ³n de la columnaÂ discounted_price:
EliminaciÃ³n del sÃ­mboloÂ â‚¹Â y comas.
ConversiÃ³n deÂ objectÂ â†’Â float64.
VerificaciÃ³n de la conversiÃ³n mostrando ejemplos antes y despuÃ©s.
ExportaciÃ³n del dataset limpio (productos_paso1.csv).

âœ… VerificaciÃ³n de la conversiÃ³n
Tipo de dato anterior:Â object
Tipo de dato nuevo:Â float64
Ejemplo de conversiÃ³n:
Antes:Â â‚¹399
DespuÃ©s:Â 399.0

ğŸ’¾ Resultado
Archivo exportado:Â productos_paso1.csv
El proceso se completÃ³ sin errores.
La columnaÂ discounted_priceÂ quedÃ³ lista para anÃ¡lisis estadÃ­stico y numÃ©rico.

codigo:
```python
#Â =============================================================================
#Â ANÃLISISÂ COMPLETOÂ DELÂ FORMATOÂ DEÂ DATOS
#Â =============================================================================

print("ğŸ”Â ANÃLISISÂ COMPLETOÂ DELÂ FORMATOÂ DEÂ DATOS")
print("="Â *Â 60)

#Â -----------------------------------------------------------------------------
#Â 1.Â FUNCIÃ“NÂ PARAÂ ANALIZARÂ UNAÂ COLUMNA
#Â -----------------------------------------------------------------------------
defÂ analizar_columna(df,Â nombre_columna,Â df_nombre):
Â Â Â Â """AnalizaÂ profundamenteÂ unaÂ columnaÂ yÂ muestraÂ ejemplos"""
Â Â Â Â print(f"\nğŸ“ŠÂ {df_nombre}Â -Â Columna:Â {nombre_columna}")
Â Â Â Â print("-"Â *Â 50)

Â Â Â Â #Â InformaciÃ³nÂ bÃ¡sica
Â Â Â Â print(f"Â Â Â TipoÂ deÂ dato:Â {df[nombre_columna].dtype}")
Â Â Â Â print(f"Â Â Â TotalÂ deÂ valores:Â {len(df[nombre_columna])}")
Â Â Â Â print(f"Â Â Â ValoresÂ nulos:Â {df[nombre_columna].isnull().sum()}")
Â Â Â Â print(f"Â Â Â ValoresÂ Ãºnicos:Â {df[nombre_columna].nunique()}")

Â Â Â Â #Â EstadÃ­sticasÂ segÃºnÂ elÂ tipoÂ deÂ dato
Â Â Â Â ifÂ df[nombre_columna].dtypeÂ inÂ ['int64',Â 'float64']:
Â Â Â Â Â Â Â Â #Â EsÂ numÃ©rico
Â Â Â Â Â Â Â Â print(f"Â Â Â MÃ­nimo:Â {df[nombre_columna].min()}")
Â Â Â Â Â Â Â Â print(f"Â Â Â MÃ¡ximo:Â {df[nombre_columna].max()}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Promedio:Â {df[nombre_columna].mean():.2f}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Mediana:Â {df[nombre_columna].median()}")

Â Â Â Â elifÂ df[nombre_columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â #Â EsÂ texto/string
Â Â Â Â Â Â Â Â longitudesÂ =Â df[nombre_columna].astype(str).str.len()
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ promedio:Â {longitudes.mean():.1f}Â caracteres")
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ mÃ­nima:Â {longitudes.min()}Â caracteres")
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ mÃ¡xima:Â {longitudes.max()}Â caracteres")

Â Â Â Â Â Â Â Â #Â MostrarÂ losÂ valoresÂ mÃ¡sÂ frecuentes
Â Â Â Â Â Â Â Â print(f"\nÂ Â Â ValoresÂ mÃ¡sÂ frecuentes:")
Â Â Â Â Â Â Â Â valores_frecuentesÂ =Â df[nombre_columna].value_counts().head(3)
Â Â Â Â Â Â Â Â forÂ valor,Â conteoÂ inÂ valores_frecuentes.items():
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â '{valor}':Â {conteo}Â veces")

Â Â Â Â #Â MostrarÂ ejemplosÂ deÂ valores
Â Â Â Â print(f"\nÂ Â Â EjemplosÂ deÂ valores:")
Â Â Â Â ejemplosÂ =Â df[nombre_columna].dropna().head(3).tolist()
Â Â Â Â forÂ i,Â ejemploÂ inÂ enumerate(ejemplos,Â 1):
Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â {i}.Â {repr(ejemplo)}")Â Â #Â repr()Â muestraÂ elÂ formatoÂ exacto

Â Â Â Â print(f"Â Â Â ...Â yÂ {len(df[nombre_columna])Â -Â 3}Â mÃ¡s")

#Â -----------------------------------------------------------------------------
#Â 2.Â ANALIZARÂ TABLAÂ PRODUCTOS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ“¦Â ANÃLISISÂ DEÂ LAÂ TABLAÂ PRODUCTOS")
print("="*60)

forÂ columnaÂ inÂ productos.columns:
Â Â Â Â analizar_columna(productos,Â columna,Â "PRODUCTOS")

#Â -----------------------------------------------------------------------------
#Â 3.Â ANALIZARÂ TABLAÂ RESEÃ‘AS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("â­Â ANÃLISISÂ DEÂ LAÂ TABLAÂ RESEÃ‘AS")
print("="*60)

forÂ columnaÂ inÂ resenas.columns:
Â Â Â Â analizar_columna(resenas,Â columna,Â "RESEÃ‘AS")

#Â -----------------------------------------------------------------------------
#Â 4.Â RESUMENÂ DEÂ TIPOSÂ DEÂ DATOS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ“‹Â RESUMENÂ DEÂ TIPOSÂ DEÂ DATOS")
print("="*60)

print("\nğŸ“¦Â PRODUCTOS:")
forÂ columnaÂ inÂ productos.columns:
Â Â Â Â print(f"Â Â Â {columna}:Â {productos[columna].dtype}")

print("\nâ­Â RESEÃ‘AS:")
forÂ columnaÂ inÂ resenas.columns:
Â Â Â Â print(f"Â Â Â {columna}:Â {resenas[columna].dtype}")

#Â -----------------------------------------------------------------------------
#Â 5.Â DETECTARÂ POSIBLESÂ PROBLEMASÂ DEÂ FORMATO
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸš¨Â DETECCIÃ“NÂ DEÂ POSIBLESÂ PROBLEMAS")
print("="*60)

#Â VerificarÂ columnasÂ queÂ deberÃ­anÂ serÂ numÃ©ricasÂ peroÂ sonÂ texto
columnas_numericas_esperadasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'rating',Â 'rating_count']

print("ColumnasÂ queÂ podrÃ­anÂ necesitarÂ conversiÃ³nÂ numÃ©rica:")
forÂ columnaÂ inÂ columnas_numericas_esperadas:
Â Â Â Â ifÂ columnaÂ inÂ productos.columnsÂ andÂ productos[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â print(f"Â Â Â ğŸ“¦Â {columna}Â (deberÃ­aÂ serÂ numÃ©rica)")
Â Â Â Â ifÂ columnaÂ inÂ resenas.columnsÂ andÂ resenas[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â print(f"Â Â Â â­Â {columna}Â (deberÃ­aÂ serÂ numÃ©rica)")

#Â -----------------------------------------------------------------------------
#Â 6.Â EJEMPLOSÂ DETALLADOSÂ DEÂ VALORES
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ”Â EJEMPLOSÂ DETALLADOSÂ PORÂ COLUMNA")
print("="*60)

defÂ mostrar_ejemplos_detallados(df,Â nombre_columna,Â n=5):
Â Â Â Â """MuestraÂ ejemplosÂ detalladosÂ deÂ unaÂ columna"""
Â Â Â Â print(f"\nğŸ“‹Â {nombre_columna}Â -Â EjemplosÂ detallados:")
Â Â Â Â valoresÂ =Â df[nombre_columna].dropna().head(n).tolist()
Â Â Â Â forÂ i,Â valorÂ inÂ enumerate(valores,Â 1):
Â Â Â Â Â Â Â Â print(f"Â Â Â {i}.Â {repr(valor)}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â Tipo:Â {type(valor)}")
Â Â Â Â Â Â Â Â ifÂ isinstance(valor,Â str):
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â Longitud:Â {len(valor)}Â caracteres")
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ any(cÂ inÂ valorÂ forÂ cÂ inÂ ['â‚¹',Â ',',Â '%']):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â ContieneÂ sÃ­mbolos:Â {[cÂ forÂ cÂ inÂ ['â‚¹',Â ',',Â '%']Â ifÂ cÂ inÂ valor]}")

#Â EjemplosÂ deÂ columnasÂ clave
print("\nğŸ“¦Â PRODUCTOSÂ -Â EjemplosÂ detallados:")
mostrar_ejemplos_detallados(productos,Â 'discounted_price')
mostrar_ejemplos_detallados(productos,Â 'actual_price')
mostrar_ejemplos_detallados(productos,Â 'discount_percentage')

print("\nâ­Â RESEÃ‘ASÂ -Â EjemplosÂ detallados:")
mostrar_ejemplos_detallados(resenas,Â 'rating')
mostrar_ejemplos_detallados(resenas,Â 'rating_count')
```

ConversiÃ³n deÂ actual_priceÂ yÂ discount_percentage
En esta etapa se abordaron lasÂ columnas restantes con problemas de formato numÃ©ricoÂ en el datasetÂ productos.
Se aplicÃ³ la limpieza de sÃ­mbolos y la conversiÃ³n a valores decimales para garantizar consistencia.

ğŸ“¦ Variables procesadas
actual_price
Inicialmente en formatoÂ objectÂ (texto).
ContenÃ­a sÃ­mbolos de rupias (â‚¹) y comas de miles.
Se eliminÃ³ la simbologÃ­a y se transformÃ³ aÂ float64.
discount_percentage
Inicialmente en formatoÂ object.
ContenÃ­a el sÃ­mboloÂ %.
Se eliminÃ³ el sÃ­mbolo y se convirtiÃ³ aÂ int64Â para trabajar con porcentajes enteros.

âœ… VerificaciÃ³n de conversiones
actual_price
Tipo anterior:Â object
Tipo nuevo:Â float64
Ejemplo:
Antes:Â â‚¹1,099
DespuÃ©s:Â 1099.0
discount_percentage
Tipo anterior:Â object
Tipo nuevo:Â int64
Ejemplo:
Antes:Â 64%
DespuÃ©s:Â 64

ğŸ’¾ Resultados
Se actualizaron los tipos de datos en el datasetÂ productos.
Nuevos archivos exportados:
```python
productos_paso2.csv
```
Con esta limpieza, los campos deÂ precios y porcentajesÂ quedaron listos para anÃ¡lisis numÃ©ricos como estadÃ­sticas, correlaciones y modelos de descuento.

codigo:
```python
#Â =============================================================================
#Â PASOÂ 1:Â CONVERTIRÂ DISCOUNTED_PRICEÂ AÂ DECIMAL
#Â =============================================================================

print("ğŸ¯Â PASOÂ 1:Â CONVERTIRÂ DISCOUNTED_PRICEÂ AÂ DECIMAL")
print("="Â *Â 60)

#Â -----------------------------------------------------------------------------
#Â 1.Â CONVERSIÃ“NÂ DIRECTA
#Â -----------------------------------------------------------------------------
print("\nğŸ”¢Â CONVIRTIENDOÂ DISCOUNTED_PRICE...")
print("-"Â *Â 40)

#Â GuardarÂ elÂ valorÂ originalÂ paraÂ referencia
#Â VerificarÂ siÂ laÂ columnaÂ originalÂ aÃºnÂ existeÂ comoÂ tipoÂ objetoÂ antesÂ deÂ guardar
ifÂ productos['discounted_price'].dtypeÂ ==Â 'object':
Â Â Â Â productos['discounted_price_original']Â =Â productos['discounted_price']
else:
Â Â Â Â print("â„¹ï¸Â 'discounted_price'Â isÂ alreadyÂ numeric,Â skippingÂ originalÂ valueÂ save.")


#Â ConvertirÂ aÂ decimalÂ (eliminarÂ â‚¹Â yÂ ,Â luegoÂ convertirÂ aÂ float)
#Â SoloÂ aplicarÂ operacionesÂ deÂ cadenaÂ siÂ laÂ columnaÂ esÂ deÂ tipoÂ objeto
ifÂ productos['discounted_price'].dtypeÂ ==Â 'object':
Â Â Â Â productos['discounted_price']Â =Â (
Â Â Â Â Â Â Â Â productos['discounted_price']
Â Â Â Â Â Â Â Â .str.replace('â‚¹',Â '',Â regex=False)Â Â Â Â #Â EliminarÂ sÃ­mboloÂ deÂ rupee
Â Â Â Â Â Â Â Â .str.replace(',',Â '',Â regex=False)Â Â Â Â Â #Â EliminarÂ comasÂ deÂ miles
Â Â Â Â Â Â Â Â .astype(float)Â Â Â Â Â Â Â Â Â Â Â Â #Â ConvertirÂ aÂ decimal
Â Â Â Â )
elifÂ productos['discounted_price'].dtypeÂ inÂ ['int64',Â 'float64']:
Â Â Â Â print("â„¹ï¸Â 'discounted_price'Â isÂ alreadyÂ numeric,Â noÂ conversionÂ needed.")
else:
Â Â Â Â #Â IntentarÂ convertirÂ aÂ numÃ©rico,Â forzandoÂ losÂ errores
Â Â Â Â productos['discounted_price']Â =Â pd.to_numeric(productos['discounted_price'],Â errors='coerce')
Â Â Â Â #Â RellenarÂ cualquierÂ NaNÂ resultanteÂ siÂ esÂ necesarioÂ (porÂ ejemplo,Â conÂ 0Â oÂ conÂ laÂ mediana)
Â Â Â Â productos['discounted_price']Â =Â productos['discounted_price'].fillna(0)Â #Â OÂ usarÂ .median()
Â Â Â Â print("â„¹ï¸Â AttemptedÂ numericÂ conversionÂ withÂ errorÂ coercionÂ andÂ NaNÂ filling.")


#Â -----------------------------------------------------------------------------
#Â 2.Â VERIFICACIÃ“NÂ MÃNIMA
#Â -----------------------------------------------------------------------------
print("âœ…Â VERIFICACIÃ“N:")
print("-"Â *Â 40)

#Â VerificarÂ siÂ 'discounted_price_original'Â existeÂ antesÂ deÂ intentarÂ imprimirÂ suÂ dtype
ifÂ 'discounted_price_original'Â inÂ productos.columns:
Â Â Â Â print(f"Â Â Â TipoÂ deÂ datoÂ anterior:Â {productos['discounted_price_original'].dtype}")

print(f"Â Â Â TipoÂ deÂ datoÂ nuevo:Â {productos['discounted_price'].dtype}")

print(f"\nÂ Â Â EjemploÂ deÂ conversiÃ³n:")
#Â AccederÂ deÂ formaÂ seguraÂ aÂ iloc[0]
ifÂ notÂ productos.empty:
Â Â Â Â ifÂ 'discounted_price_original'Â inÂ productos.columns:
Â Â Â Â Â Â Â Â print(f"Â Â Â Antes:Â {productos['discounted_price_original'].iloc[0]}")
Â Â Â Â print(f"Â Â Â DespuÃ©s:Â {productos['discounted_price'].iloc[0]}")
else:
Â Â Â Â print("Â Â Â DataFrameÂ isÂ empty,Â cannotÂ showÂ examples.")


#Â -----------------------------------------------------------------------------
#Â 3.Â GUARDAR
#Â -----------------------------------------------------------------------------
print("\nğŸ’¾Â GUARDANDO:")
print("-"Â *Â 40)

#Â GuardarÂ elÂ DataFrameÂ actualizado
productos.to_csv("productos_paso1.csv",Â index=False)
print("Â Â Â âœ…Â ArchivoÂ guardado:Â productos_paso1.csv")


print("Â Â Â discounted_priceÂ convertidoÂ exitosamenteÂ deÂ objectÂ aÂ decimal")
print("Â Â Â NoÂ seÂ realizaronÂ anÃ¡lisisÂ niÂ cÃ¡lculosÂ adicionales")
```

5. Limpieza y ConversiÃ³n de Columnas NumÃ©ricas
En esta etapa se trabajÃ³ sobre las variables que originalmente estaban en formato de texto pero que en realidad representan valoresÂ numÃ©ricosÂ (precios, descuentos y calificaciones).
El objetivo fue transformarlas en un formato adecuado (float64Â oÂ int64) para permitir cÃ¡lculos y anÃ¡lisis estadÃ­sticos posteriores.

ğŸ“Š Estado Inicial
Productos:Â 1351 filas, 19 columnas.
ReseÃ±as:Â 1194 filas, 16 columnas.
Se identificÃ³ que las siguientes columnas requerÃ­an limpieza:
```python
productos:Â actual_price,Â discount_percentage.
resenas:Â rating.
```

ğŸ”§ Proceso de ConversiÃ³n
Guardar copia de los datos originales
Si la columna era de tipoÂ objectÂ (texto), se creÃ³ una columna auxiliarÂ *_originalÂ para conservar los valores previos.
Limpieza de sÃ­mbolos
EnÂ actual_price: se eliminaron el sÃ­mboloÂ â‚¹Â y las comas de miles.
EnÂ discount_percentage: se eliminÃ³ el sÃ­mboloÂ %.
EnÂ rating: se eliminaron espacios y valores vacÃ­os.
ConversiÃ³n a valores numÃ©ricos
```python
Se utilizÃ³Â pd.to_numeric()Â para transformar los datos.
```
Valores invÃ¡lidos se convirtieron enÂ NaN.
Posteriormente se rellenaron (fillna) con:
0Â en precios y porcentajes.
MedianaÂ en el caso deÂ rating, para mantener coherencia en los anÃ¡lisis.
VerificaciÃ³n final
actual_priceÂ â†’Â float64.
discount_percentageÂ â†’Â int64.
ratingÂ â†’Â float64.

âœ… Resultado Final
Productos:
discounted_priceÂ (float64)
actual_priceÂ (float64)
discount_percentageÂ (int64)
ReseÃ±as:
ratingÂ (float64)
rating_countÂ (int64)

ğŸ’¾ Guardado de Resultados
Se generaron dos nuevos archivos con los datos ya procesados:
amazon_productos_numerico.csv
amazon_resenas_numerico.csv
Estos archivos contienen las columnas numÃ©ricas listas para anÃ¡lisis, sin riesgo de errores por sÃ­mbolos o formatos incorrectos.


codigo:
```python
#Â =============================================================================
#Â LIMPIEZAÂ YÂ CONVERSIÃ“NÂ DEÂ COLUMNASÂ NUMÃ‰RICASÂ RESTANTES
#Â =============================================================================

print("ğŸ¯Â LIMPIEZAÂ YÂ CONVERSIÃ“NÂ DEÂ COLUMNASÂ NUMÃ‰RICASÂ RESTANTES")
print("="Â *Â 70)

#Â GuardarÂ elÂ estadoÂ inicialÂ paraÂ comparar
print("ğŸ“ŠÂ ESTADOÂ INICIAL:")
print(f"Â Â Â Productos:Â {productos.shape[0]}Â filas,Â {productos.shape[1]}Â columnas")
print(f"Â Â Â ReseÃ±as:Â {resenas.shape[0]}Â filas,Â {resenas.shape[1]}Â columnas")

print("\nğŸ”Â TiposÂ deÂ datosÂ iniciales:")
print("Â Â Â Productos:")
print(productos[['actual_price',Â 'discount_percentage']].dtypes)
print("\nÂ Â Â ReseÃ±as:")
print(resenas[['rating']].dtypes)


#Â -----------------------------------------------------------------------------
#Â 1.Â PROCESARÂ COLUMNASÂ ENÂ PRODUCTOSÂ (actual_price,Â discount_percentage)
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ“¦Â PROCESANDOÂ TABLAÂ PRODUCTOS")
print("="*60)

columnas_productos_a_convertirÂ =Â ['actual_price',Â 'discount_percentage']

forÂ columnaÂ inÂ columnas_productos_a_convertir:
Â Â Â Â print(f"\nğŸ”¢Â ConvirtiendoÂ columna:Â {columna}")
Â Â Â Â print("-"Â *Â 40)

Â Â Â Â ifÂ columnaÂ inÂ productos.columns:
Â Â Â Â Â Â Â Â #Â GuardarÂ elÂ valorÂ originalÂ siÂ aÃºnÂ esÂ object
Â Â Â Â Â Â Â Â ifÂ productos[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â Â Â Â Â productos[f'{columna}_original']Â =Â productos[columna]
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â GuardadoÂ '{columna}_original'Â (tipo:Â {productos[f'{columna}_original'].dtype})")
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â '{columna}'Â yaÂ esÂ numÃ©rico,Â omitiendoÂ guardarÂ originalÂ comoÂ object.")


Â Â Â Â Â Â Â Â #Â LimpiezaÂ yÂ conversiÃ³n
Â Â Â Â Â Â Â Â ifÂ productos[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â Â Â Â Â #Â AplicarÂ limpiezaÂ soloÂ siÂ esÂ string/object
Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â (
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â .str.replace('â‚¹',Â '',Â regex=False)Â Â Â Â #Â EliminarÂ sÃ­mboloÂ deÂ rupee
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â .str.replace(',',Â '',Â regex=False)Â Â Â Â Â #Â EliminarÂ comasÂ deÂ miles
Â Â Â Â Â Â Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ columnaÂ ==Â 'discount_percentage':
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â productos[columna].str.replace('%',Â '',Â regex=False)Â #Â EliminarÂ %

Â Â Â Â Â Â Â Â Â Â Â Â #Â ConvertirÂ aÂ numÃ©rico,Â forzandoÂ erroresÂ aÂ NaN
Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â pd.to_numeric(productos[columna],Â errors='coerce')

Â Â Â Â Â Â Â Â Â Â Â Â #Â RellenarÂ NaNÂ resultantesÂ siÂ esÂ necesarioÂ (ej.Â conÂ 0Â oÂ mediana)
Â Â Â Â Â Â Â Â Â Â Â Â #Â ParaÂ preciosÂ yÂ porcentajes,Â 0Â oÂ NaNÂ podrÃ­anÂ serÂ opcionesÂ vÃ¡lidasÂ dependiendoÂ delÂ contexto.
Â Â Â Â Â Â Â Â Â Â Â Â #Â AquÃ­Â optamosÂ porÂ 0Â paraÂ simplicidad,Â peroÂ NaNÂ podrÃ­aÂ serÂ preferibleÂ paraÂ anÃ¡lisisÂ estadÃ­sticos.
Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â productos[columna].fillna(0)Â #Â OÂ .median()Â oÂ dejarÂ comoÂ NaNÂ siÂ seÂ prefiere

Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â âœ…Â LimpiezaÂ yÂ conversiÃ³nÂ completadaÂ paraÂ '{columna}'")

Â Â Â Â Â Â Â Â elifÂ productos[columna].dtypeÂ inÂ ['int64',Â 'float64']:
Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â '{columna}'Â yaÂ esÂ numÃ©rico,Â noÂ seÂ necesitaÂ limpiezaÂ deÂ sÃ­mbolos.")
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â #Â IntentoÂ generalÂ deÂ conversiÃ³nÂ siÂ elÂ tipoÂ noÂ esÂ objectÂ niÂ numÃ©ricoÂ conocido
Â Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â pd.to_numeric(productos[columna],Â errors='coerce')
Â Â Â Â Â Â Â Â Â Â Â Â Â productos[columna]Â =Â productos[columna].fillna(0)Â #Â ManejarÂ posiblesÂ erroresÂ deÂ conversiÃ³nÂ aÂ NaN
Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â IntentandoÂ conversiÃ³nÂ numÃ©ricaÂ generalÂ conÂ manejoÂ deÂ erroresÂ paraÂ '{columna}'.")


Â Â Â Â Â Â Â Â #Â VerificarÂ tipoÂ deÂ datoÂ finalÂ yÂ mostrarÂ ejemplo
Â Â Â Â Â Â Â Â print(f"Â Â Â TipoÂ deÂ datoÂ final:Â {productos[columna].dtype}")
Â Â Â Â Â Â Â Â ifÂ notÂ productos.empty:
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â EjemploÂ deÂ valorÂ convertido:Â {productos[columna].iloc[0]}")
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â print("Â Â Â DataFrameÂ isÂ empty,Â cannotÂ showÂ examples.")

Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"Â Â Â âš ï¸Â ColumnaÂ '{columna}'Â noÂ encontradaÂ enÂ elÂ DataFrameÂ deÂ productos.")


#Â -----------------------------------------------------------------------------
#Â 2.Â PROCESARÂ COLUMNASÂ ENÂ RESEÃ‘ASÂ (rating)
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("â­Â PROCESANDOÂ TABLAÂ RESEÃ‘AS")
print("="*60)

columna_resenas_a_convertirÂ =Â 'rating'

ifÂ columna_resenas_a_convertirÂ inÂ resenas.columns:
Â Â Â Â print(f"\nğŸ”¢Â ConvirtiendoÂ columna:Â {columna_resenas_a_convertir}")
Â Â Â Â print("-"Â *Â 40)

Â Â Â Â #Â GuardarÂ elÂ valorÂ originalÂ siÂ aÃºnÂ esÂ object
Â Â Â Â ifÂ resenas[columna_resenas_a_convertir].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â resenas[f'{columna_resenas_a_convertir}_original']Â =Â resenas[columna_resenas_a_convertir]
Â Â Â Â Â Â Â Â print(f"Â Â Â GuardadoÂ '{columna_resenas_a_convertir}_original'Â (tipo:Â {resenas[f'{columna_resenas_a_convertir}_original'].dtype})")
Â Â Â Â else:
Â Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â '{columna_resenas_a_convertir}'Â yaÂ esÂ numÃ©rico,Â omitiendoÂ guardarÂ originalÂ comoÂ object.")


Â Â Â Â #Â LimpiezaÂ yÂ conversiÃ³n
Â Â Â Â ifÂ resenas[columna_resenas_a_convertir].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â Â #Â AplicarÂ limpiezaÂ soloÂ siÂ esÂ string/object
Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]Â =Â (
Â Â Â Â Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]
Â Â Â Â Â Â Â Â Â Â Â Â .astype(str)Â #Â AsegurarÂ queÂ esÂ stringÂ paraÂ .strÂ mÃ©todos
Â Â Â Â Â Â Â Â Â Â Â Â .str.strip()Â #Â LimpiarÂ espacios
Â Â Â Â Â Â Â Â Â Â Â Â .replace('',Â 'NaN')Â #Â RemplazarÂ vacÃ­osÂ conÂ NaNÂ paraÂ queÂ to_numericÂ losÂ maneje
Â Â Â Â Â Â Â Â )

Â Â Â Â Â Â Â Â #Â ConvertirÂ aÂ numÃ©rico
Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]Â =Â pd.to_numeric(resenas[columna_resenas_a_convertir],Â errors='coerce')

Â Â Â Â Â Â Â Â #Â RellenarÂ NaNÂ resultantesÂ (losÂ ratingsÂ nulosÂ oÂ conÂ errorÂ seÂ conviertenÂ aÂ NaN)
Â Â Â Â Â Â Â Â #Â RellenarÂ conÂ unÂ valorÂ comoÂ laÂ medianaÂ oÂ laÂ mediaÂ podrÃ­aÂ serÂ unaÂ opciÃ³nÂ siÂ seÂ quiereÂ conservarÂ filas,
Â Â Â Â Â Â Â Â #Â peroÂ eliminarÂ filasÂ conÂ ratingÂ desconocidoÂ tambiÃ©nÂ esÂ vÃ¡lido.
Â Â Â Â Â Â Â Â #Â AquÃ­Â rellenamosÂ conÂ laÂ medianaÂ comoÂ ejemplo,Â peroÂ consideraÂ laÂ mejorÂ estrategiaÂ paraÂ elÂ anÃ¡lisis.
Â Â Â Â Â Â Â Â median_ratingÂ =Â resenas[columna_resenas_a_convertir].median()
Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]Â =Â resenas[columna_resenas_a_convertir].fillna(median_rating)

Â Â Â Â Â Â Â Â print(f"Â Â Â âœ…Â LimpiezaÂ yÂ conversiÃ³nÂ completadaÂ paraÂ '{columna_resenas_a_convertir}'")

Â Â Â Â elifÂ resenas[columna_resenas_a_convertir].dtypeÂ inÂ ['int64',Â 'float64']:
Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â '{columna_resenas_a_convertir}'Â yaÂ esÂ numÃ©rico,Â noÂ seÂ necesitaÂ conversiÃ³n.")
Â Â Â Â else:
Â Â Â Â Â Â Â Â Â #Â IntentoÂ generalÂ deÂ conversiÃ³nÂ siÂ elÂ tipoÂ noÂ esÂ objectÂ niÂ numÃ©ricoÂ conocido
Â Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]Â =Â pd.to_numeric(resenas[columna_resenas_a_convertir],Â errors='coerce')
Â Â Â Â Â Â Â Â Â median_ratingÂ =Â resenas[columna_resenas_a_convertir].median()
Â Â Â Â Â Â Â Â Â resenas[columna_resenas_a_convertir]Â =Â resenas[columna_resenas_a_convertir].fillna(median_rating)
Â Â Â Â Â Â Â Â Â print(f"Â Â Â â„¹ï¸Â IntentandoÂ conversiÃ³nÂ numÃ©ricaÂ generalÂ conÂ manejoÂ deÂ erroresÂ paraÂ '{columna_resenas_a_convertir}'.")


Â Â Â Â #Â VerificarÂ tipoÂ deÂ datoÂ finalÂ yÂ mostrarÂ ejemplo
Â Â Â Â print(f"Â Â Â TipoÂ deÂ datoÂ final:Â {resenas[columna_resenas_a_convertir].dtype}")
Â Â Â Â ifÂ notÂ resenas.empty:
Â Â Â Â Â Â Â Â print(f"Â Â Â EjemploÂ deÂ valorÂ convertido:Â {resenas[columna_resenas_a_convertir].iloc[0]}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("Â Â Â DataFrameÂ isÂ empty,Â cannotÂ showÂ examples.")

else:
Â Â Â Â print(f"Â Â Â âš ï¸Â ColumnaÂ '{columna_resenas_a_convertir}'Â noÂ encontradaÂ enÂ elÂ DataFrameÂ deÂ reseÃ±as.")


#Â -----------------------------------------------------------------------------
#Â 3.Â VERIFICACIÃ“NÂ FINALÂ DEÂ TIPOSÂ DEÂ DATOS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*70)
print("âœ…Â VERIFICACIÃ“NÂ FINALÂ DEÂ TIPOSÂ DEÂ DATOS")
print("="*70)

print("\nğŸ“¦Â PRODUCTOSÂ -Â TiposÂ deÂ datosÂ finales:")
print(productos[['discounted_price',Â 'actual_price',Â 'discount_percentage']].dtypes)

print("\nâ­Â RESEÃ‘ASÂ -Â TiposÂ deÂ datosÂ finales:")
print(resenas[['rating',Â 'rating_count']].dtypes)Â #Â IncluimosÂ rating_countÂ queÂ yaÂ fueÂ limpiado

#Â -----------------------------------------------------------------------------
#Â 4.Â GUARDARÂ DATOSÂ LIMPIOSÂ (OPCIONAL)
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*70)
print("ğŸ’¾Â GUARDANDOÂ DATOSÂ LIMPIOS")
print("="*70)

productos.to_csv("amazon_productos_numerico.csv",Â index=False)
resenas.to_csv("amazon_resenas_numerico.csv",Â index=False)
print("Â Â Â âœ…Â ArchivosÂ guardados:")
print("Â Â Â Â Â Â -Â amazon_productos_numerico.csv")
print("Â Â Â Â Â Â -Â amazon_resenas_numerico.csv")

print("\nğŸ‰Â Â¡LimpiezaÂ yÂ conversiÃ³nÂ deÂ columnasÂ numÃ©ricasÂ completada!")
```

6. ConversiÃ³n deÂ rating_originalÂ a Entero
En este paso se trabajÃ³ con la columnaÂ rating_originalÂ de la tabla de reseÃ±as.
Originalmente, esta variable tenÃ­a valores en formatoÂ objectÂ oÂ float, representando puntuaciones con decimales (ejemplo:Â 4.2).
El objetivo fueÂ convertirla a un formato entero (int64), adecuado para anÃ¡lisis categÃ³ricos o estadÃ­sticos que no requieran decimales.

ğŸ“Š Proceso Realizado
```python
ConversiÃ³n robusta conÂ pd.to_numeric()
```
Se utilizÃ³ esta funciÃ³n conÂ errors='coerce'Â para manejar cualquier valor no numÃ©rico.
Los valores invÃ¡lidos se transformaron enÂ NaN.
Manejo de valores nulos
LosÂ NaNÂ se rellenaron conÂ 0Â antes de convertir a enteros.
Esta decisiÃ³n asegura consistencia en el dataset, aunque puede ajustarse segÃºn el anÃ¡lisis (ejemplo: eliminar o imputar con media/mediana).
TransformaciÃ³n final
La columnaÂ rating_originalÂ se transformÃ³ a tipoÂ int64.
Se creÃ³ tambiÃ©n la columna auxiliarÂ rating_original_numericÂ para conservar los valores en formato decimal antes de redondear.

âœ… Resultado
Tipo de dato anterior:Â objectÂ oÂ float.
Tipo de dato nuevo:Â int64.
Ejemplo de conversiÃ³n:
Antes:Â 4.2
DespuÃ©s:Â 4

ğŸ’¾ Guardado de Resultados
El DataFrame actualizado se almacenÃ³ en el archivo:
```python
resenas_paso2.csv
```
Este archivo ya contiene la columnaÂ rating_originalÂ transformada a enteros, lista para su uso en anÃ¡lisis posteriores.

ğŸ¯ ConclusiÃ³n
Con esta limpieza:
rating_originalÂ queda en un formato uniforme (int64).
Se garantiza mayor facilidad para anÃ¡lisis que requieran agrupaciones, conteos o categorizaciÃ³n de calificaciones.

codigo:
```python
#Â =============================================================================
#Â PASOÂ 2:Â CONVERTIRÂ RATING_ORIGINALÂ AÂ ENTERO
#Â =============================================================================

print("ğŸ¯Â PASOÂ 2:Â CONVERTIRÂ RATING_ORIGINALÂ AÂ ENTERO")
print("="Â *Â 60)

#Â -----------------------------------------------------------------------------
#Â 1.Â CONVERSIÃ“N
#Â -----------------------------------------------------------------------------
print("\nğŸ”¢Â CONVIRTIENDOÂ RATING_ORIGINAL...")
print("-"Â *Â 40)

#Â UsarÂ pd.to_numericÂ paraÂ unaÂ conversiÃ³nÂ robusta,Â forzandoÂ losÂ errores
resenas['rating_original_numeric']Â =Â pd.to_numeric(resenas['rating_original'],Â errors='coerce')

#Â ConvertirÂ laÂ columnaÂ numÃ©ricaÂ aÂ entero,Â rellenandoÂ primeroÂ losÂ NaNsÂ siÂ esÂ necesario
#Â RellenarÂ losÂ NaNsÂ conÂ 0Â antesÂ deÂ convertirÂ aÂ int.Â AjustarÂ elÂ valorÂ deÂ fillnaÂ siÂ esÂ necesario.
resenas['rating_original']Â =Â resenas['rating_original_numeric'].fillna(0).astype(int)


#Â -----------------------------------------------------------------------------
#Â 2.Â VERIFICACIÃ“NÂ MÃNIMA
#Â -----------------------------------------------------------------------------
print("âœ…Â VERIFICACIÃ“N:")
print("-"Â *Â 40)

#Â VerificaÂ elÂ tipoÂ deÂ datoÂ (dtype)Â deÂ laÂ columnaÂ antesÂ yÂ despuÃ©sÂ delÂ intentoÂ deÂ conversiÃ³nÂ enÂ estaÂ celda
#Â EsÂ difÃ­cilÂ saberÂ elÂ estadoÂ exactoÂ "antesÂ deÂ esteÂ paso"Â sinÂ volverÂ aÂ ejecutarÂ lasÂ celdasÂ anteriores,
#Â asÃ­Â queÂ indicaremosÂ elÂ estadoÂ esperadoÂ enÂ baseÂ alÂ errorÂ yÂ alÂ objetivo.
print(f"Â Â Â TipoÂ deÂ datoÂ anteriorÂ (antesÂ deÂ esteÂ paso):Â objectÂ oÂ float")
print(f"Â Â Â TipoÂ deÂ datoÂ nuevo:Â {resenas['rating_original'].dtype}")

print(f"\nÂ Â Â EjemploÂ deÂ conversiÃ³n:")
#Â AccederÂ deÂ formaÂ seguraÂ aÂ iloc[0]Â yÂ manejarÂ posiblesÂ NaNs
ifÂ notÂ resenas.empty:
Â Â Â Â #Â IntentoÂ deÂ mostrarÂ unÂ valorÂ deÂ laÂ columnaÂ numÃ©ricaÂ intermediaÂ paraÂ comparaciÃ³n
Â Â Â Â ifÂ 'rating_original_numeric'Â inÂ resenas.columnsÂ andÂ pd.notna(resenas['rating_original_numeric'].iloc[0]):
Â Â Â Â Â Â Â Â print(f"Â Â Â AntesÂ (valorÂ numÃ©ricoÂ intermedio):Â {resenas['rating_original_numeric'].iloc[0]}")
Â Â Â Â elifÂ 'rating_original_backup'Â inÂ resenas.columnsÂ andÂ pd.notna(resenas['rating_original_backup'].iloc[0]):
Â Â Â Â Â Â Â Â Â print(f"Â Â Â AntesÂ (backupÂ original):Â {resenas['rating_original_backup'].iloc[0]}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("Â Â Â Antes:Â (ValorÂ originalÂ noÂ disponibleÂ oÂ eraÂ NaN)")

Â Â Â Â print(f"Â Â Â DespuÃ©s:Â {resenas['rating_original'].iloc[0]}")
else:
Â Â Â Â print("Â Â Â DataFrameÂ estÃ¡Â vacÃ­o,Â noÂ seÂ puedenÂ mostrarÂ ejemplos.")


#Â -----------------------------------------------------------------------------
#Â 3.Â GUARDARÂ SINÂ ANÃLISISÂ ADICIONAL
#Â -----------------------------------------------------------------------------
print("\nğŸ’¾Â GUARDANDO:")
print("-"Â *Â 40)

#Â GuardarÂ elÂ DataFrameÂ actualizado
resenas.to_csv("resenas_paso2.csv",Â index=False)
print("Â Â Â âœ…Â ArchivoÂ guardado:Â resenas_paso2.csv")

print(f"\nğŸ‰Â Â¡PASOÂ 2Â COMPLETADO!")
print("Â Â Â rating_originalÂ convertidoÂ exitosamenteÂ aÂ enteroÂ (manejandoÂ decimalesÂ yÂ errores)")
print("Â Â Â NoÂ seÂ realizaronÂ anÃ¡lisisÂ niÂ cÃ¡lculosÂ adicionales")
```

VerificaciÃ³n de Nulos y Duplicados
Con el fin de garantizar laÂ calidad y consistencia de los datosÂ antes de realizar cualquier anÃ¡lisis avanzado, se efectuÃ³ una revisiÃ³n sistemÃ¡tica de:
Valores Nulos (NaN)
Se inspeccionaron todas las columnas de las tablasÂ ProductosÂ yÂ ReseÃ±as.
El objetivo fue identificar posibles datos faltantes que pudieran distorsionar los resultados de cÃ¡lculos, mÃ©tricas o visualizaciones.
En caso de encontrarlos, se definieron estrategias de manejo como:
EliminaciÃ³n de registros incompletos.
Relleno con valores estadÃ­sticos (media, mediana o moda).
SustituciÃ³n con un valor neutro (ejemplo:Â 0Â en columnas numÃ©ricas).
Registros Duplicados
Se evaluaron ambas tablas para identificar filas repetidas.
En particular, se verificaron los campos clave:
Productos:Â product_id
ReseÃ±as:Â review_id
Los duplicados encontrados se eliminaron, conservando una sola ocurrencia de cada registro Ãºnico.

codigo:
```python
#Â =============================================================================
#Â ANÃLISISÂ COMPLETOÂ DELÂ FORMATOÂ DEÂ DATOS
#Â =============================================================================

print("ğŸ”Â ANÃLISISÂ COMPLETOÂ DELÂ FORMATOÂ DEÂ DATOS")
print("="Â *Â 60)

#Â -----------------------------------------------------------------------------
#Â 1.Â FUNCIÃ“NÂ PARAÂ ANALIZARÂ UNAÂ COLUMNA
#Â -----------------------------------------------------------------------------
defÂ analizar_columna(df,Â nombre_columna,Â df_nombre):
Â Â Â Â """AnalizaÂ profundamenteÂ unaÂ columnaÂ yÂ muestraÂ ejemplos"""
Â Â Â Â print(f"\nğŸ“ŠÂ {df_nombre}Â -Â Columna:Â {nombre_columna}")
Â Â Â Â print("-"Â *Â 50)

Â Â Â Â #Â InformaciÃ³nÂ bÃ¡sica
Â Â Â Â print(f"Â Â Â TipoÂ deÂ dato:Â {df[nombre_columna].dtype}")
Â Â Â Â print(f"Â Â Â TotalÂ deÂ valores:Â {len(df[nombre_columna])}")
Â Â Â Â print(f"Â Â Â ValoresÂ nulos:Â {df[nombre_columna].isnull().sum()}")
Â Â Â Â print(f"Â Â Â ValoresÂ Ãºnicos:Â {df[nombre_columna].nunique()}")

Â Â Â Â #Â EstadÃ­sticasÂ segÃºnÂ elÂ tipoÂ deÂ dato
Â Â Â Â ifÂ df[nombre_columna].dtypeÂ inÂ ['int64',Â 'float64']:
Â Â Â Â Â Â Â Â #Â EsÂ numÃ©rico
Â Â Â Â Â Â Â Â print(f"Â Â Â MÃ­nimo:Â {df[nombre_columna].min()}")
Â Â Â Â Â Â Â Â print(f"Â Â Â MÃ¡ximo:Â {df[nombre_columna].max()}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Promedio:Â {df[nombre_columna].mean():.2f}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Mediana:Â {df[nombre_columna].median()}")

Â Â Â Â elifÂ df[nombre_columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â #Â EsÂ texto/string
Â Â Â Â Â Â Â Â longitudesÂ =Â df[nombre_columna].astype(str).str.len()
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ promedio:Â {longitudes.mean():.1f}Â caracteres")
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ mÃ­nima:Â {longitudes.min()}Â caracteres")
Â Â Â Â Â Â Â Â print(f"Â Â Â LongitudÂ mÃ¡xima:Â {longitudes.max()}Â caracteres")

Â Â Â Â Â Â Â Â #Â MostrarÂ losÂ valoresÂ mÃ¡sÂ frecuentes
Â Â Â Â Â Â Â Â print(f"\nÂ Â Â ValoresÂ mÃ¡sÂ frecuentes:")
Â Â Â Â Â Â Â Â valores_frecuentesÂ =Â df[nombre_columna].value_counts().head(3)
Â Â Â Â Â Â Â Â forÂ valor,Â conteoÂ inÂ valores_frecuentes.items():
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â '{valor}':Â {conteo}Â veces")

Â Â Â Â #Â MostrarÂ ejemplosÂ deÂ valores
Â Â Â Â print(f"\nÂ Â Â EjemplosÂ deÂ valores:")
Â Â Â Â ejemplosÂ =Â df[nombre_columna].dropna().head(3).tolist()
Â Â Â Â forÂ i,Â ejemploÂ inÂ enumerate(ejemplos,Â 1):
Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â {i}.Â {repr(ejemplo)}")Â Â #Â repr()Â muestraÂ elÂ formatoÂ exacto

Â Â Â Â print(f"Â Â Â ...Â yÂ {len(df[nombre_columna])Â -Â 3}Â mÃ¡s")

#Â -----------------------------------------------------------------------------
#Â 2.Â ANALIZARÂ TABLAÂ PRODUCTOS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ“¦Â ANÃLISISÂ DEÂ LAÂ TABLAÂ PRODUCTOS")
print("="*60)

forÂ columnaÂ inÂ productos.columns:
Â Â Â Â analizar_columna(productos,Â columna,Â "PRODUCTOS")

#Â -----------------------------------------------------------------------------
#Â 3.Â ANALIZARÂ TABLAÂ RESEÃ‘AS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("â­Â ANÃLISISÂ DEÂ LAÂ TABLAÂ RESEÃ‘AS")
print("="*60)

forÂ columnaÂ inÂ resenas.columns:
Â Â Â Â analizar_columna(resenas,Â columna,Â "RESEÃ‘AS")

#Â -----------------------------------------------------------------------------
#Â 4.Â RESUMENÂ DEÂ TIPOSÂ DEÂ DATOS
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ“‹Â RESUMENÂ DEÂ TIPOSÂ DEÂ DATOS")
print("="*60)

print("\nğŸ“¦Â PRODUCTOS:")
forÂ columnaÂ inÂ productos.columns:
Â Â Â Â print(f"Â Â Â {columna}:Â {productos[columna].dtype}")

print("\nâ­Â RESEÃ‘AS:")
forÂ columnaÂ inÂ resenas.columns:
Â Â Â Â print(f"Â Â Â {columna}:Â {resenas[columna].dtype}")

#Â -----------------------------------------------------------------------------
#Â 5.Â DETECTARÂ POSIBLESÂ PROBLEMASÂ DEÂ FORMATO
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸš¨Â DETECCIÃ“NÂ DEÂ POSIBLESÂ PROBLEMAS")
print("="*60)

#Â VerificarÂ columnasÂ queÂ deberÃ­anÂ serÂ numÃ©ricasÂ peroÂ sonÂ texto
columnas_numericas_esperadasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'rating',Â 'rating_count']

print("ColumnasÂ queÂ podrÃ­anÂ necesitarÂ conversiÃ³nÂ numÃ©rica:")
forÂ columnaÂ inÂ columnas_numericas_esperadas:
Â Â Â Â ifÂ columnaÂ inÂ productos.columnsÂ andÂ productos[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â print(f"Â Â Â ğŸ“¦Â {columna}Â (deberÃ­aÂ serÂ numÃ©rica)")
Â Â Â Â ifÂ columnaÂ inÂ resenas.columnsÂ andÂ resenas[columna].dtypeÂ ==Â 'object':
Â Â Â Â Â Â Â Â print(f"Â Â Â â­Â {columna}Â (deberÃ­aÂ serÂ numÃ©rica)")

#Â -----------------------------------------------------------------------------
#Â 6.Â EJEMPLOSÂ DETALLADOSÂ DEÂ VALORES
#Â -----------------------------------------------------------------------------
print("\n"Â +Â "="*60)
print("ğŸ”Â EJEMPLOSÂ DETALLADOSÂ PORÂ COLUMNA")
print("="*60)

defÂ mostrar_ejemplos_detallados(df,Â nombre_columna,Â n=5):
Â Â Â Â """MuestraÂ ejemplosÂ detalladosÂ deÂ unaÂ columna"""
Â Â Â Â print(f"\nğŸ“‹Â {nombre_columna}Â -Â EjemplosÂ detallados:")
Â Â Â Â valoresÂ =Â df[nombre_columna].dropna().head(n).tolist()
Â Â Â Â forÂ i,Â valorÂ inÂ enumerate(valores,Â 1):
Â Â Â Â Â Â Â Â print(f"Â Â Â {i}.Â {repr(valor)}")
Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â Tipo:Â {type(valor)}")
Â Â Â Â Â Â Â Â ifÂ isinstance(valor,Â str):
Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â Longitud:Â {len(valor)}Â caracteres")
Â Â Â Â Â Â Â Â Â Â Â Â ifÂ any(cÂ inÂ valorÂ forÂ cÂ inÂ ['â‚¹',Â ',',Â '%']):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"Â Â Â Â Â Â ContieneÂ sÃ­mbolos:Â {[cÂ forÂ cÂ inÂ ['â‚¹',Â ',',Â '%']Â ifÂ cÂ inÂ valor]}")

#Â EjemplosÂ deÂ columnasÂ clave
print("\nğŸ“¦Â PRODUCTOSÂ -Â EjemplosÂ detallados:")
mostrar_ejemplos_detallados(productos,Â 'discounted_price')
mostrar_ejemplos_detallados(productos,Â 'actual_price')
mostrar_ejemplos_detallados(productos,Â 'discount_percentage')

print("\nâ­Â RESEÃ‘ASÂ -Â EjemplosÂ detallados:")
mostrar_ejemplos_detallados(resenas,Â 'rating')
mostrar_ejemplos_detallados(resenas,Â 'rating_count')
```

codigo:
```python
#Â VerificarÂ siÂ quedanÂ duplicadosÂ enÂ product_idÂ despuÃ©sÂ deÂ laÂ limpieza
duplicados_id_prod_despuesÂ =Â productos['product_id'].duplicated().sum()

print(f"DuplicadosÂ restantesÂ enÂ product_idÂ enÂ laÂ tablaÂ productos:Â {duplicados_id_prod_despues}")

ifÂ duplicados_id_prod_despuesÂ >Â 0:
Â Â Â Â print("\nâš ï¸Â Â AÃºnÂ hayÂ product_idÂ duplicados.Â MostrarÂ ejemplos:")
Â Â Â Â ids_duplicados_finalÂ =Â productos[productos['product_id'].duplicated(keep=False)]['product_id'].unique()
Â Â Â Â productos_duplicados_finalÂ =Â productos[productos['product_id'].isin(ids_duplicados_final)]
Â Â Â Â display(productos_duplicados_final.sort_values('product_id'))
else:
Â Â Â Â print("âœ…Â NoÂ hayÂ product_idÂ duplicadosÂ restantesÂ enÂ laÂ tablaÂ productos.")
```

7. IdentificaciÃ³n y Manejo de Valores Fuera de Alcance
En esta etapa se buscÃ³ asegurar que las variables numÃ©ricas se encuentren dentro de unÂ rango lÃ³gico y vÃ¡lido.
El enfoque consistiÃ³ en dos pasos:

VerificaciÃ³n deÂ discount_percentage
Se evaluÃ³ si existÃ­an registros con valores deÂ descuento menores a 0% o mayores a 100%.
Este control es necesario ya que, en tÃ©rminos prÃ¡cticos, no deberÃ­a existir un descuento negativo ni uno que supere el 100%.
ğŸ“ŠÂ Resultado:
NÃºmero de registros fuera de rango:Â 0
âœ… No se encontraron valores anÃ³malos en la columnaÂ discount_percentage.

codigo:
```python
#Â DetectarÂ registrosÂ conÂ discount_percentageÂ fueraÂ delÂ rangoÂ esperadoÂ (Â <Â 0Â oÂ >Â 100)
registros_fuera_rangoÂ =Â productos[(productos['discount_percentage']Â <Â 0)Â |Â (productos['discount_percentage']Â >Â 100)]

print(f"NÃºmeroÂ deÂ registrosÂ conÂ discount_percentageÂ fueraÂ delÂ rangoÂ esperado:Â {len(registros_fuera_rango)}")

ifÂ notÂ registros_fuera_rango.empty:
Â Â Â Â print("\nRegistrosÂ conÂ discount_percentageÂ fueraÂ delÂ rangoÂ esperado:")
Â Â Â Â display(registros_fuera_rango)
else:
Â Â Â Â print("\nâœ…Â NoÂ seÂ encontraronÂ registrosÂ conÂ discount_percentageÂ fueraÂ delÂ rangoÂ esperadoÂ (0-100).")
```

ConfirmaciÃ³n de Columnas NumÃ©ricas para AnÃ¡lisis de Outliers
Se identificaron las columnas numÃ©ricas en las que posteriormente se aplicarÃ¡ la detecciÃ³n deÂ outliersÂ (valores atÃ­picos):
Productos:
discounted_priceÂ â†’ tipoÂ float64
actual_priceÂ â†’ tipoÂ float64
discount_percentageÂ â†’ tipoÂ int64
ReseÃ±as:
ratingÂ â†’ tipoÂ float64
rating_countÂ â†’ tipoÂ int64
ğŸ“Œ Estas serÃ¡n las variables base sobre las que se calcularÃ¡n mÃ©tricas estadÃ­sticas (comoÂ IQR, cuartiles y lÃ­mites de detecciÃ³n de outliers) en pasos posteriores.

ğŸ¯ ConclusiÃ³n
La validaciÃ³n confirma queÂ no existen valores fuera de rangoÂ enÂ discount_percentage.
Se han establecido claramente lasÂ columnas numÃ©ricas claveÂ para el anÃ¡lisis estadÃ­stico y detecciÃ³n de valores atÃ­picos.

codigo:
```python
print("DataÂ typesÂ ofÂ numericÂ columnsÂ inÂ 'productos':")
print(productos[['discounted_price',Â 'actual_price',Â 'discount_percentage']].dtypes)

print("\nDataÂ typesÂ ofÂ numericÂ columnsÂ inÂ 'resenas':")
print(resenas[['rating',Â 'rating_count']].dtypes)
```

8. IdentificaciÃ³n y Manejo de Outliers
En este paso se aplicaronÂ dos mÃ©todos complementariosÂ para detectar valores atÃ­picos (outliers) en las columnas numÃ©ricas de los datasets:
Z-ScoreÂ (considerando |Z| > 3 como umbral)
Rango IntercuartÃ­lico (IQR)Â (Q1 - 1.5IQR, Q3 + 1.5IQR)

8.1 Columnas Analizadas
ğŸ“¦Â Productos
discounted_price
actual_price
discount_percentage
â­Â ReseÃ±as
rating
rating_count

8.2 Resultados
Z-Score
Productos:Â 44 outliers
ReseÃ±as:Â 38 outliers
IQR
Productos:Â 219 outliers
ReseÃ±as:Â 140 outliers
ğŸ“Œ El mÃ©todo IQR identificÃ³ un nÃºmeroÂ significativamente mayorÂ de outliers que Z-Score. Esto ocurre porque IQR es mÃ¡s sensible a valores que se encuentran fuera del rango intercuartÃ­lico, aunque no sean extremadamente atÃ­picos en tÃ©rminos de desviaciones estÃ¡ndar.

8.3 Observaciones
Precios (discounted_price,Â actual_price):
Los outliers detectados por Z-Score corresponden a productos de gama alta (ej. televisores, laptops premium).
El mÃ©todo IQR detectÃ³ ademÃ¡s precios menos extremos pero igualmente alejados de la mediana.
Porcentaje de Descuento (discount_percentage):
Confirmado que los valores estÃ¡n dentro del rango 0-100%.
Los outliers corresponden a descuentos muy agresivos (ej. > 80%), posiblemente promociones especiales o valores anÃ³malos.
Rating (rating):
Como estÃ¡ en escala de 1 a 5, Z-Score no detectÃ³ casos extremos.
IQR seÃ±alÃ³ algunos valores en los lÃ­mites (1 o 5 estrellas), que son vÃ¡lidos en el contexto.
Conteo de Ratings (rating_count):
Z-Score identificÃ³ productos con un nÃºmero extremadamente alto de reseÃ±as.
IQR seÃ±alÃ³ ademÃ¡s valores intermedios pero aÃºn altos.
Estos datos suelen ser representativos de productos populares (best-sellers).

8.4 Estrategias de Manejo
Precios:
Investigar manualmente los casos mÃ¡s extremos detectados por Z-Score.
Aplicar transformaciÃ³n logarÃ­tmica para reducir el sesgo en anÃ¡lisis y modelos.
Porcentaje de Descuento:
Mantener valores (excepto que se detecten errores).
Pueden ser informativos sobre estrategias de precios.
Rating:
Mantener todos los registros, pues reflejan valoraciones reales.
Conteo de Ratings:
No eliminar, ya que representan popularidad real.
Aplicar transformaciÃ³n logarÃ­tmica para suavizar la asimetrÃ­a.

8.5 ConclusiÃ³n
El anÃ¡lisis muestra que:
IQR es mÃ¡s sensible, seÃ±alando mÃ¡s casos como outliers.
Z-Score es mÃ¡s conservador, enfocÃ¡ndose en valores extremadamente atÃ­picos.
La estrategia elegida buscaÂ equilibrar robustez estadÃ­stica y realismo de negocio, evitando la eliminaciÃ³n masiva de registros y priorizando la transformaciÃ³n de variables cuando sea necesario.

codigo:
```python
fromÂ scipy.statsÂ importÂ zscore

#Â CalculoÂ Z-scoresÂ paraÂ 'productos'
productos['discounted_price_zscore']Â =Â zscore(productos['discounted_price'])
productos['actual_price_zscore']Â =Â zscore(productos['actual_price'])
productos['discount_percentage_zscore']Â =Â zscore(productos['discount_percentage'])

#Â CalculoÂ Z-scoresÂ paraÂ 'resenas'
resenas['rating_zscore']Â =Â zscore(resenas['rating'])
resenas['rating_count_zscore']Â =Â zscore(resenas['rating_count'])

print("Z-ScoresÂ calculatedÂ for:")
print("-Â productos:Â discounted_price,Â actual_price,Â discount_percentage")
print("-Â resenas:Â rating,Â rating_count")

#Â DisplayÂ theÂ firstÂ fewÂ rowsÂ toÂ showÂ theÂ newÂ columns
print("\nProductosÂ withÂ Z-scores:")
display(productos.head())

print("\nResenasÂ withÂ Z-scores:")
display(resenas.head())
```

Razonamiento: Identificar posibles valores atÃ­picos utilizando un umbral de puntuaciÃ³n Z (por ejemplo, |Z-score| > 3) para las columnas numÃ©ricas especificadas en ambos DataFrames.

codigo:
z_score_thresholdÂ =Â 3

#Â IdentificarÂ outliersÂ enÂ 'productos'Â basadoÂ encZ-score
outliers_productos_zscoreÂ =Â productos[
Â Â Â Â (abs(productos['discounted_price_zscore'])Â >Â z_score_threshold)Â |
Â Â Â Â (abs(productos['actual_price_zscore'])Â >Â z_score_threshold)Â |
Â Â Â Â (abs(productos['discount_percentage_zscore'])Â >Â z_score_threshold)
]

print(f"\nOutliersÂ identifiedÂ inÂ 'productos'Â usingÂ Z-scoreÂ (thresholdÂ =Â {z_score_threshold}):")
print(f"NumberÂ ofÂ outliers:Â {len(outliers_productos_zscore)}")
ifÂ notÂ outliers_productos_zscore.empty:
Â Â Â Â display(outliers_productos_zscore)
else:
Â Â Â Â print("NoÂ outliersÂ foundÂ inÂ 'productos'Â usingÂ Z-score.")


#Â IdentificarÂ outliersÂ enÂ 'resenas'Â basadoÂ enÂ Z-score
outliers_resenas_zscoreÂ =Â resenas[
Â Â Â Â (abs(resenas['rating_zscore'])Â >Â z_score_threshold)Â |
Â Â Â Â (abs(resenas['rating_count_zscore'])Â >Â z_score_threshold)
]

print(f"\nOutliersÂ identifiedÂ inÂ 'resenas'Â usingÂ Z-scoreÂ (thresholdÂ =Â {z_score_threshold}):")
print(f"NumberÂ ofÂ outliers:Â {len(outliers_resenas_zscore)}")
ifÂ notÂ outliers_resenas_zscore.empty:
Â Â Â Â display(outliers_resenas_zscore)
else:
Â Â Â Â print("NoÂ outliersÂ foundÂ inÂ 'resenas'Â usingÂ Z-score.")

Razonamiento: Calcular el IQR (Rango IntercuartÃ­lico) y los lÃ­mites para la detecciÃ³n de valores atÃ­picos en las columnas numÃ©ricas especificadas de ambos DataFrames

codigo:
```python
#Â CalculoÂ IQRÂ yÂ limitesÂ paraÂ 'productos'
forÂ colÂ inÂ ['discounted_price',Â 'actual_price',Â 'discount_percentage']:
Â Â Â Â Q1Â =Â productos[col].quantile(0.25)
Â Â Â Â Q3Â =Â productos[col].quantile(0.75)
Â Â Â Â IQRÂ =Â Q3Â -Â Q1
Â Â Â Â lower_boundÂ =Â Q1Â -Â 1.5Â *Â IQR
Â Â Â Â upper_boundÂ =Â Q3Â +Â 1.5Â *Â IQR

Â Â Â Â productos[f'{col}_iqr_lower']Â =Â lower_bound
Â Â Â Â productos[f'{col}_iqr_upper']Â =Â upper_bound

Â Â Â Â print(f"\nIQRÂ andÂ boundsÂ forÂ '{col}'Â inÂ 'productos':")
Â Â Â Â print(f"Â Â Q1:Â {Q1:.2f}")
Â Â Â Â print(f"Â Â Q3:Â {Q3:.2f}")
Â Â Â Â print(f"Â Â IQR:Â {IQR:.2f}")
Â Â Â Â print(f"Â Â LowerÂ Bound:Â {lower_bound:.2f}")
Â Â Â Â print(f"Â Â UpperÂ Bound:Â {upper_bound:.2f}")


#Â CalculoÂ IQRÂ limitesÂ paraÂ Â Â 'resenas'
forÂ colÂ inÂ ['rating',Â 'rating_count']:
Â Â Â Â Q1Â =Â resenas[col].quantile(0.25)
Â Â Â Â Q3Â =Â resenas[col].quantile(0.75)
Â Â Â Â IQRÂ =Â Q3Â -Â Q1
Â Â Â Â lower_boundÂ =Â Q1Â -Â 1.5Â *Â IQR
Â Â Â Â upper_boundÂ =Â Q3Â +Â 1.5Â *Â IQR

Â Â Â Â resenas[f'{col}_iqr_lower']Â =Â lower_bound
Â Â Â Â resenas[f'{col}_iqr_upper']Â =Â upper_bound

Â Â Â Â print(f"\nIQRÂ andÂ boundsÂ forÂ '{col}'Â inÂ 'resenas':")
Â Â Â Â print(f"Â Â Q1:Â {Q1:.2f}")
Â Â Â Â print(f"Â Â Q3:Â {Q3:.2f}")
Â Â Â Â print(f"Â Â IQR:Â {IQR:.2f}")
Â Â Â Â print(f"Â Â LowerÂ Bound:Â {lower_bound:.2f}")
Â Â Â Â print(f"Â Â UpperÂ Bound:Â {upper_bound:.2f}")

print("\nIQRÂ boundsÂ calculatedÂ andÂ addedÂ toÂ dataframes.")
```

Razonamiento: Identifique posibles valores atÃ­picos utilizando los lÃ­mites del RIQ calculados para las columnas numÃ©ricas especificadas en ambos marcos de datos.

codigo:
```python
#Â identificarÂ outliersÂ enÂ 'productos'Â basadoÂ enÂ IQR
outliers_productos_iqrÂ =Â productos[
Â Â Â Â (productos['discounted_price']Â <Â productos['discounted_price_iqr_lower'])Â |
Â Â Â Â (productos['discounted_price']Â >Â productos['discounted_price_iqr_upper'])Â |
Â Â Â Â (productos['actual_price']Â <Â productos['actual_price_iqr_lower'])Â |
Â Â Â Â (productos['actual_price']Â >Â productos['actual_price_iqr_upper'])Â |
Â Â Â Â (productos['discount_percentage']Â <Â productos['discount_percentage_iqr_lower'])Â |
Â Â Â Â (productos['discount_percentage']Â >Â productos['discount_percentage_iqr_upper'])
]

print("\nOutliersÂ identifiedÂ inÂ 'productos'Â usingÂ IQR:")
print(f"NumberÂ ofÂ outliers:Â {len(outliers_productos_iqr)}")
ifÂ notÂ outliers_productos_iqr.empty:
Â Â Â Â display(outliers_productos_iqr)
else:
Â Â Â Â print("NoÂ outliersÂ foundÂ inÂ 'productos'Â usingÂ IQR.")


#Â identificarÂ outliersÂ enÂ 'resenas'Â basadoÂ enÂ IQR
outliers_resenas_iqrÂ =Â resenas[
Â Â Â Â (resenas['rating']Â <Â resenas['rating_iqr_lower'])Â |
Â Â Â Â (resenas['rating']Â >Â resenas['rating_iqr_upper'])Â |
Â Â Â Â (resenas['rating_count']Â <Â resenas['rating_count_iqr_lower'])Â |
Â Â Â Â (resenas['rating_count']Â >Â resenas['rating_count_iqr_upper'])
]

print("\nOutliersÂ identifiedÂ inÂ 'resenas'Â usingÂ IQR:")
print(f"NumberÂ ofÂ outliers:Â {len(outliers_resenas_iqr)}")
ifÂ notÂ outliers_resenas_iqr.empty:
Â Â Â Â display(outliers_resenas_iqr)
else:
Â Â Â Â print("NoÂ outliersÂ foundÂ inÂ 'resenas'Â usingÂ IQR.")
```

Razonamiento: Imprima la cantidad de valores atÃ­picos encontrados por cada mÃ©todo y muestre las primeras filas de los marcos de datos de valores atÃ­picos para comparar.

codigo:
```python
print("NÃºmeroÂ deÂ outliersÂ encontradosÂ porÂ mÃ©todo:")
print(f"Â Â ProductosÂ (Z-Score):Â {len(outliers_productos_zscore)}")
print(f"Â Â ProductosÂ (IQR):Â {len(outliers_productos_iqr)}")
print(f"Â Â ReseÃ±asÂ (Z-Score):Â {len(outliers_resenas_zscore)}")
print(f"Â Â ReseÃ±asÂ (IQR):Â {len(outliers_resenas_iqr)}")

print("\nPrimerasÂ filasÂ deÂ OutliersÂ (Z-Score)Â -Â Productos:")
ifÂ notÂ outliers_productos_zscore.empty:
Â Â Â Â display(outliers_productos_zscore.head())
else:
Â Â Â Â print("NoÂ hayÂ outliersÂ enÂ productosÂ segÃºnÂ Z-Score.")

print("\nPrimerasÂ filasÂ deÂ OutliersÂ (Z-Score)Â -Â ReseÃ±as:")
ifÂ notÂ outliers_resenas_zscore.empty:
Â Â Â Â display(outliers_resenas_zscore.head())
else:
Â Â Â Â print("NoÂ hayÂ outliersÂ enÂ reseÃ±asÂ segÃºnÂ Z-Score.")

print("\nPrimerasÂ filasÂ deÂ OutliersÂ (IQR)Â -Â Productos:")
ifÂ notÂ outliers_productos_iqr.empty:
Â Â Â Â display(outliers_productos_iqr.head())
else:
Â Â Â Â print("NoÂ hayÂ outliersÂ enÂ productosÂ segÃºnÂ IQR.")

print("\nPrimerasÂ filasÂ deÂ OutliersÂ (IQR)Â -Â ReseÃ±as:")
ifÂ notÂ outliers_resenas_iqr.empty:
Â Â Â Â display(outliers_resenas_iqr.head())
else:
Â Â Â Â print("NoÂ hayÂ outliersÂ enÂ reseÃ±asÂ segÃºnÂ IQR.")

print("\nObservacionesÂ sobreÂ lasÂ diferencias:")
print("-Â ElÂ mÃ©todoÂ IQRÂ identificaÂ unÂ nÃºmeroÂ significativamenteÂ mayorÂ deÂ outliersÂ enÂ ambasÂ tablasÂ enÂ comparaciÃ³nÂ conÂ elÂ mÃ©todoÂ Z-ScoreÂ (usandoÂ unÂ umbralÂ deÂ 3).")
print("-Â EstoÂ sugiereÂ queÂ hayÂ muchosÂ valoresÂ queÂ caenÂ fueraÂ delÂ rangoÂ intercuartÃ­licoÂ (Q1Â -Â 1.5*IQRÂ aÂ Q3Â +Â 1.5*IQR)Â peroÂ queÂ noÂ sonÂ extremadamenteÂ atÃ­picosÂ (esÂ decir,Â noÂ tienenÂ unÂ Z-ScoreÂ >Â 3).")
print("-Â LasÂ filasÂ mostradasÂ confirmanÂ queÂ losÂ outliersÂ identificadosÂ porÂ IQRÂ aÂ menudoÂ tienenÂ valoresÂ menosÂ extremosÂ queÂ losÂ identificadosÂ porÂ Z-Score.")
```

Considerar el tratamiento de outliers
Subtask:
Discutir posibles estrategias para manejar los outliers encontrados (ej. eliminarlos, transformarlos, dejarlos como estÃ¡n dependiendo del anÃ¡lisis posterior).

Reasoning: Discuss the outlier handling strategies based on the previous analysis and propose a preliminary strategy for this project.

codigo:
```python
print("##Â DiscusiÃ³nÂ yÂ EstrategiaÂ paraÂ elÂ ManejoÂ deÂ Outliers")
print("="Â *Â 60)

print("\n###Â ResumenÂ deÂ OutliersÂ Encontrados:")
print(f"-Â ProductosÂ (Z-ScoreÂ >Â 3):Â {len(outliers_productos_zscore)}Â outliers")
print(f"-Â ProductosÂ (IQR):Â {len(outliers_productos_iqr)}Â outliers")
print(f"-Â ReseÃ±asÂ (Z-ScoreÂ >Â 3):Â {len(outliers_resenas_zscore)}Â outliers")
print(f"-Â ReseÃ±asÂ (IQR):Â {len(outliers_resenas_iqr)}Â outliers")

print("\n###Â ImpactoÂ PotencialÂ deÂ losÂ Outliers:")
print("-Â **PreciosÂ (discounted_price,Â actual_price):**Â OutliersÂ enÂ preciosÂ puedenÂ sesgarÂ estadÃ­sticasÂ descriptivasÂ (media,Â desviaciÃ³nÂ estÃ¡ndar)Â yÂ afectarÂ modelosÂ queÂ sonÂ sensiblesÂ aÂ laÂ escalaÂ (ej.,Â regresiÃ³nÂ lineal,Â clusteringÂ basadoÂ enÂ distancia).Â PreciosÂ muyÂ altosÂ oÂ muyÂ bajosÂ podrÃ­anÂ representarÂ productosÂ deÂ lujo/gamaÂ bajaÂ oÂ erroresÂ deÂ entrada.")
print("-Â **PorcentajeÂ deÂ DescuentoÂ (discount_percentage):**Â OutliersÂ aquÃ­Â podrÃ­anÂ indicarÂ descuentosÂ inusualmenteÂ altosÂ oÂ bajos,Â posiblementeÂ erroresÂ oÂ promocionesÂ especiales.Â PuedenÂ afectarÂ anÃ¡lisisÂ deÂ rentabilidadÂ oÂ modelosÂ deÂ predicciÃ³nÂ deÂ ventas.")
print("-Â **RatingÂ (rating):**Â AunqueÂ losÂ ratingsÂ suelenÂ estarÂ enÂ unaÂ escalaÂ limitadaÂ (ej.,Â 1-5),Â outliersÂ (siÂ losÂ hubiera,Â aunqueÂ enÂ esteÂ casoÂ noÂ seÂ encontraronÂ conÂ Z-score>3Â oÂ IQR)Â podrÃ­anÂ serÂ erroresÂ deÂ entradaÂ oÂ reseÃ±asÂ fraudulentas.Â EnÂ esteÂ dataset,Â losÂ ratingsÂ parecenÂ estarÂ dentroÂ deÂ unÂ rangoÂ esperado,Â aunqueÂ IQRÂ identificÃ³Â algunosÂ valoresÂ enÂ losÂ extremosÂ comoÂ outliers.")
print("-Â **ConteoÂ deÂ RatingsÂ (rating_count):**Â OutliersÂ enÂ elÂ conteoÂ deÂ ratingsÂ sonÂ comunesÂ yÂ aÂ menudoÂ representanÂ productosÂ muyÂ populares.Â EliminarÂ estosÂ podrÃ­aÂ llevarÂ aÂ laÂ pÃ©rdidaÂ deÂ informaciÃ³nÂ valiosaÂ sobreÂ elÂ rendimientoÂ deÂ losÂ productos.Â PuedenÂ sesgarÂ anÃ¡lisisÂ basadosÂ enÂ promediosÂ simplesÂ oÂ afectarÂ modelosÂ queÂ asumenÂ distribucionesÂ normales.")

print("\n###Â EstrategiasÂ PotencialesÂ paraÂ elÂ ManejoÂ deÂ Outliers:")
print("1.Â Â **EliminaciÃ³n:**Â SimpleÂ yÂ directa.Â AdecuadaÂ siÂ losÂ outliersÂ sonÂ pocosÂ yÂ claramenteÂ errores.Â Riesgo:Â pÃ©rdidaÂ deÂ datosÂ yÂ posibleÂ distorsiÃ³nÂ deÂ laÂ distribuciÃ³nÂ siÂ losÂ outliersÂ sonÂ genuinos.")
print("2.Â Â **TransformaciÃ³n:**Â AplicarÂ transformacionesÂ (ej.,Â logarÃ­tmica,Â raÃ­zÂ cuadrada)Â paraÂ reducirÂ elÂ sesgoÂ yÂ laÂ influenciaÂ deÂ losÂ valoresÂ extremos.Â ÃštilÂ paraÂ columnasÂ conÂ distribucionesÂ muyÂ asimÃ©tricasÂ (comoÂ rating_count).")
print("3.Â Â **Capping/Winsorizing:**Â ReemplazarÂ losÂ valoresÂ extremosÂ porÂ unÂ percentilÂ especificadoÂ (ej.,Â 5ÂºÂ yÂ 95ÂºÂ percentil).Â MantieneÂ elÂ nÃºmeroÂ deÂ filasÂ peroÂ reduceÂ laÂ variabilidadÂ extrema.Â MenosÂ agresivoÂ queÂ laÂ eliminaciÃ³n.")
print("4.Â Â **MantenerÂ Outliers:**Â SiÂ losÂ outliersÂ representanÂ eventosÂ oÂ caracterÃ­sticasÂ realesÂ eÂ importantesÂ (ej.,Â unÂ productoÂ conÂ unÂ nÃºmeroÂ excepcionalmenteÂ altoÂ deÂ reseÃ±asÂ porÂ serÂ unÂ best-seller),Â mantenerlosÂ puedeÂ serÂ crucialÂ paraÂ unaÂ comprensiÃ³nÂ completaÂ delÂ dataset.")

print("\n###Â PropuestaÂ deÂ EstrategiaÂ PreliminarÂ paraÂ esteÂ Proyecto:")
print("DadaÂ laÂ naturalezaÂ deÂ losÂ datosÂ deÂ e-commerceÂ yÂ losÂ tiposÂ deÂ outliersÂ encontrados:")
print("1.Â Â **PreciosÂ (discounted_price,Â actual_price):**Â LosÂ outliersÂ identificadosÂ porÂ IQRÂ sonÂ numerosos.Â EsÂ probableÂ queÂ muchosÂ representenÂ productosÂ deÂ gamaÂ altaÂ legÃ­timos.Â EliminarÂ tantosÂ datosÂ noÂ esÂ deseable.Â ElÂ Z-scoreÂ identificaÂ losÂ preciosÂ mÃ¡sÂ extremos,Â queÂ *podrÃ­an*Â serÂ errores.Â SugieroÂ investigarÂ manualmenteÂ algunosÂ deÂ losÂ outliersÂ deÂ Z-ScoreÂ mÃ¡sÂ extremosÂ paraÂ verificarÂ suÂ validez.Â ParaÂ anÃ¡lisisÂ oÂ modelosÂ sensiblesÂ aÂ laÂ escala,Â seÂ podrÃ­aÂ considerarÂ laÂ **transformaciÃ³nÂ logarÃ­tmica**Â deÂ estasÂ columnasÂ enÂ lugarÂ deÂ laÂ eliminaciÃ³nÂ oÂ cappingÂ masivo.")
print("2.Â Â **PorcentajeÂ deÂ DescuentoÂ (discount_percentage):**Â ElÂ rangoÂ yaÂ fueÂ verificadoÂ (0-100).Â LosÂ outliersÂ identificadosÂ (principalmenteÂ porÂ IQR)Â puedenÂ representarÂ descuentosÂ muyÂ agresivos.Â EsÂ importanteÂ entenderÂ siÂ sonÂ vÃ¡lidos.Â PodrÃ­amosÂ **mantenerÂ estosÂ outliers**Â inicialmente,Â aÂ menosÂ queÂ unaÂ investigaciÃ³nÂ manualÂ reveleÂ erroresÂ claros,Â yaÂ queÂ puedenÂ serÂ informativosÂ sobreÂ laÂ estrategiaÂ deÂ precios.")
print("3.Â Â **RatingÂ (rating):**Â LosÂ outliersÂ identificadosÂ (soloÂ porÂ IQRÂ enÂ losÂ extremosÂ deÂ laÂ escalaÂ 1-5)Â sonÂ pocos.Â DadoÂ queÂ laÂ escalaÂ esÂ limitada,Â **mantenerÂ estosÂ valores**Â pareceÂ razonable,Â yaÂ queÂ representanÂ ratingsÂ realesÂ (1Â estrellaÂ oÂ 5Â estrellas).Â LaÂ transformaciÃ³nÂ noÂ esÂ necesariaÂ paraÂ estaÂ columna.")
print("4.Â Â **ConteoÂ deÂ RatingsÂ (rating_count):**Â EstaÂ columnaÂ muestraÂ unaÂ fuerteÂ asimetrÃ­aÂ yÂ muchosÂ outliersÂ segÃºnÂ IQRÂ yÂ Z-Score.Â EstosÂ outliersÂ representanÂ productosÂ muyÂ popularesÂ yÂ sonÂ datosÂ valiosos.Â **EliminarlosÂ serÃ­aÂ perjudicial.**Â UnaÂ **transformaciÃ³nÂ logarÃ­tmica**Â esÂ laÂ estrategiaÂ mÃ¡sÂ adecuadaÂ paraÂ manejarÂ laÂ asimetrÃ­aÂ yÂ reducirÂ laÂ influenciaÂ deÂ losÂ valoresÂ extremosÂ enÂ anÃ¡lisisÂ oÂ modelos,Â mientrasÂ seÂ conservaÂ todaÂ laÂ informaciÃ³n.")

print("\n###Â EstrategiaÂ PropuestaÂ Resumida:")
print("1.Â Â **Precios:**Â InvestigarÂ outliersÂ Z-ScoreÂ extremos.Â ConsiderarÂ **transformaciÃ³nÂ logarÃ­tmica**Â paraÂ anÃ¡lisisÂ sensibles.")
print("2.Â Â **PorcentajeÂ deÂ Descuento:**Â **Mantener**Â (aÂ menosÂ queÂ seÂ identifiquenÂ erroresÂ manuales).")
print("3.Â Â **Rating:**Â **Mantener**.")
print("4.Â Â **ConteoÂ deÂ Ratings:**Â AplicarÂ **transformaciÃ³nÂ logarÃ­tmica**.")

print("\nEstaÂ estrategiaÂ buscaÂ equilibrarÂ laÂ necesidadÂ deÂ manejarÂ valoresÂ extremosÂ paraÂ elÂ anÃ¡lisisÂ estadÃ­sticoÂ yÂ elÂ modeladoÂ conÂ laÂ importanciaÂ deÂ conservarÂ datosÂ realesÂ yÂ potencialmenteÂ informativos.")
```

Resumen: IdentificaciÃ³n de Outliers en Datos de Comercio ElectrÃ³nico
Este anÃ¡lisis se centrÃ³ en identificarÂ outliers (valores atÃ­picos)Â en variables numÃ©ricas clave:
discounted_price
actual_price
discount_percentage
rating
rating_count
Se trabajÃ³ con los DataFramesÂ productosÂ yÂ resenas, aplicando dos mÃ©todos:
PuntuaciÃ³n Z (Z-Score)Â con umbral |Z| > 3
Rango IntercuartÃ­lico (IQR)Â con regla 1.5*IQR

ğŸ”‘ Hallazgos Clave
VariaciÃ³n segÃºn el mÃ©todo:
Productos:Â 44Â outliers por Z-Score vs.Â 219Â por IQR
ReseÃ±as:Â 38Â outliers por Z-Score vs.Â 140Â por IQR
Naturaleza de los outliers:
Z-Score â†’ valores mÃ¡s extremos.
IQR â†’ incluye valores alejados de la mediana, incluso si no son muy extremos.
Patrones especÃ­ficos:
rating_count: muy asimÃ©trico. Pocos productos concentran la mayorÃ­a de las reseÃ±as.
Variables de precio (discounted_price,Â actual_price): gran nÃºmero de outliers con IQR, especialmente en productos de gama alta.
LÃ­mites calculados (IQR):
Se agregaron columnas con los lÃ­mites inferior y superior en ambos DataFrames para todas las variables analizadas.

ğŸš€ Perspectivas y PrÃ³ximos Pasos
LaÂ estrategia de manejo de outliersÂ debe adaptarse a cada variable segÃºn su naturaleza y el tipo de anÃ¡lisis o modelo que se aplique.
TransformaciÃ³n logarÃ­tmicaÂ es recomendable para:
rating_countÂ (muy sesgado)
Variables de precio (para reducir el impacto de los valores extremos)
Mantener outliers vÃ¡lidos:
Ratings extremos (1 y 5 estrellas) â†’ reflejan experiencias reales.
Productos con muchas reseÃ±as â†’ representan popularidad y no deben eliminarse.
En resumen, los outliers en comercio electrÃ³nico no siempre son errores; muchas veces sonÂ informativosÂ y aportan valor al anÃ¡lisis.

9. FusiÃ³n de Tablas y Reordenamiento de Columnas
En este paso se realizÃ³ laÂ fusiÃ³n de los DataFramesÂ resenasÂ yÂ productosÂ usando la clave comÃºnÂ product_id.
Se aplicÃ³ unÂ inner join, lo cual asegura que solo se incluyan:
Productos que tienen al menos una reseÃ±a.
ReseÃ±as que corresponden a un producto existente en la tabla de productos.
De esta manera, se mantiene la coherencia entre ambos conjuntos de datos y se eliminan entradas huÃ©rfanas.

ğŸ“ Reordenamiento de Columnas
Posteriormente, se definiÃ³ unÂ orden lÃ³gico de columnasÂ para facilitar el anÃ¡lisis, agrupando:
InformaciÃ³n del usuario y reseÃ±as (user_id,Â user_name,Â review_id,Â review_title,Â review_content)
InformaciÃ³n del producto (product_id,Â product_name,Â category,Â about_product)
Variables numÃ©ricas de interÃ©s (discounted_price,Â actual_price,Â discount_percentage,Â rating,Â rating_count)

âœ… Resultados de la FusiÃ³n
Forma del DataFrame fusionado:Â (1194, 14)
Columnas resultantes en el orden solicitado:

codigo:
```python
importÂ pandasÂ asÂ pd

#Â FusionarÂ losÂ DataFramesÂ resenasÂ yÂ productosÂ usandoÂ 'product_id'
#Â UsamosÂ unÂ innerÂ joinÂ paraÂ incluirÂ soloÂ losÂ productosÂ queÂ tienenÂ reseÃ±asÂ yÂ lasÂ reseÃ±asÂ queÂ correspondenÂ aÂ unÂ productoÂ existente
#Â AseguramosÂ queÂ resenasÂ esÂ laÂ tablaÂ izquierdaÂ paraÂ mantenerÂ susÂ columnasÂ primeroÂ porÂ defectoÂ antesÂ deÂ reordenar
df_fusionadoÂ =Â pd.merge(resenas,Â productos,Â on='product_id',Â how='inner')

#Â DefinirÂ elÂ ordenÂ deseadoÂ deÂ lasÂ columnas
#Â AsegÃºrateÂ deÂ queÂ losÂ nombresÂ deÂ lasÂ columnasÂ coincidenÂ exactamenteÂ conÂ losÂ deÂ tusÂ DataFrames
orden_columnasÂ =Â [
Â Â Â Â 'user_id',
Â Â Â Â 'user_name',
Â Â Â Â 'review_id',Â #Â CorregidoÂ deÂ 'Review_id'
Â Â Â Â 'review_title',Â #Â CorregidoÂ deÂ 'Review_title'
Â Â Â Â 'review_content',Â #Â CorregidoÂ deÂ 'Review_content'
Â Â Â Â 'product_id',Â #Â CorregidoÂ deÂ 'Product_id'
Â Â Â Â 'product_name',
Â Â Â Â 'category',
Â Â Â Â 'discounted_price',
Â Â Â Â 'actual_price',
Â Â Â Â 'discount_percentage',
Â Â Â Â 'about_product',
Â Â Â Â 'rating',Â #Â CorregidoÂ deÂ 'Rating'
Â Â Â Â 'rating_count'Â #Â CorregidoÂ deÂ 'Rating_count'
]

#Â ReordenarÂ lasÂ columnasÂ delÂ DataFrameÂ fusionado
#Â VerificarÂ queÂ todasÂ lasÂ columnasÂ deseadasÂ existenÂ enÂ elÂ DataFrameÂ fusionado
columnas_existentesÂ =Â [colÂ forÂ colÂ inÂ orden_columnasÂ ifÂ colÂ inÂ df_fusionado.columns]

#Â ReordenarÂ elÂ DataFrameÂ conÂ lasÂ columnasÂ existentesÂ enÂ elÂ ordenÂ especificado
df_fusionadoÂ =Â df_fusionado[columnas_existentes]


print("âœ…Â TablasÂ fusionadasÂ exitosamenteÂ yÂ columnasÂ reordenadas.")
print(f"\nFormaÂ delÂ DataFrameÂ fusionado:Â {df_fusionado.shape}")

print("\nColumnasÂ delÂ DataFrameÂ fusionadoÂ enÂ elÂ ordenÂ solicitado:")
print(df_fusionado.columns.tolist())

print("\nPrimerasÂ filasÂ delÂ DataFrameÂ fusionado:")
display(df_fusionado.head())
```

Guardado y Renombramiento del DataFrame Final
Una vez fusionadas las tablas deÂ productosÂ yÂ reseÃ±as, se procediÃ³ a:
Guardar el DataFrameÂ df_fusionadoÂ en un archivo CSVÂ llamado:Â tabla union.csv

codigo:
```python
#Â GuardarÂ elÂ DataFrameÂ fusionadoÂ aÂ unÂ archivoÂ CSV
df_fusionado.to_csv("tablaÂ union.csv",Â index=False)

print("âœ…Â DataFrameÂ fusionadoÂ guardadoÂ exitosamenteÂ comoÂ 'tablaÂ union.csv'")
```

codigo:
```python
importÂ pandasÂ asÂ pd

#Â VerificarÂ siÂ elÂ DataFrameÂ df_fusionadoÂ existeÂ antesÂ deÂ intentarÂ renombrarlo
ifÂ 'df_fusionado'Â inÂ globals()Â andÂ isinstance(globals()['df_fusionado'],Â pd.DataFrame):
Â Â Â Â #Â CambiarÂ elÂ nombreÂ delÂ DataFrame
Â Â Â Â tabla_unionÂ =Â df_fusionado

Â Â Â Â #Â Opcional:Â EliminarÂ elÂ DataFrameÂ antiguoÂ paraÂ evitarÂ confusionesÂ (soloÂ siÂ fueÂ exitosoÂ elÂ renombramiento)
Â Â Â Â #Â UsamosÂ unÂ bloqueÂ try-exceptÂ enÂ casoÂ deÂ queÂ delÂ falleÂ porÂ algunaÂ razÃ³nÂ inesperada
Â Â Â Â try:
Â Â Â Â Â Â Â Â delÂ df_fusionado
Â Â Â Â Â Â Â Â print("Â Â Â âœ…Â DataFrameÂ 'df_fusionado'Â eliminadoÂ despuÃ©sÂ deÂ renombrar.")
Â Â Â Â exceptÂ NameError:
Â Â Â Â Â Â Â Â print("Â Â Â â„¹ï¸Â ElÂ DataFrameÂ 'df_fusionado'Â noÂ pudoÂ serÂ eliminado,Â podrÃ­aÂ noÂ haberÂ existidoÂ previamente.")


Â Â Â Â print("âœ…Â ElÂ DataFrameÂ 'df_fusionado'Â haÂ sidoÂ renombradoÂ exitosamenteÂ aÂ 'tabla_union'.")

Â Â Â Â #Â VerificarÂ siÂ elÂ nuevoÂ DataFrameÂ tabla_unionÂ existe
Â Â Â Â ifÂ 'tabla_union'Â inÂ globals()Â andÂ isinstance(globals()['tabla_union'],Â pd.DataFrame):
Â Â Â Â Â Â Â Â print("VerificaciÃ³n:Â ElÂ DataFrameÂ 'tabla_union'Â estÃ¡Â disponible.")
Â Â Â Â Â Â Â Â print(f"FormaÂ deÂ 'tabla_union':Â {tabla_union.shape}")Â #Â MostrarÂ laÂ formaÂ comoÂ verificaciÃ³n
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âš ï¸Â Error:Â ElÂ DataFrameÂ 'tabla_union'Â noÂ pareceÂ haberseÂ creadoÂ correctamente.")

else:
Â Â Â Â print("âŒÂ Error:Â ElÂ DataFrameÂ 'df_fusionado'Â noÂ seÂ encontrÃ³Â enÂ elÂ entorno.")
Â Â Â Â print("AsegÃºrateÂ deÂ haberÂ ejecutadoÂ laÂ celdaÂ dondeÂ seÂ creaÂ df_fusionado.")
```

10. Agrupar datos segÃºn rangos deÂ discount_percentage
ğŸ¯ Objetivo
Dividir los productos enÂ rangos de descuentoÂ basados en los cuartiles de la distribuciÃ³n deÂ discount_percentage.
Esto permite analizar cÃ³mo varÃ­an mÃ©tricas clave (precio, descuentos, ratings) segÃºn los distintos niveles de rebaja.

ğŸ”¹ CÃ¡lculo de Cuartiles
Se calcularon los cuartiles (Q1, Q2 y Q3) de la variableÂ discount_percentage:
Q1 (25%): 31.25
Q2 (50% o Mediana): 49.00
Q3 (75%): 62.00
ğŸ“Œ InterpretaciÃ³n:
El 25% de los productos tiene un descuento â‰¤ 31.25%.
El 50% de los productos tiene un descuento â‰¤ 49% (mediana).
El 75% de los productos tiene un descuento â‰¤ 62%.

ğŸ”¹ DefiniciÃ³n de Rangos (Bins)
Con los valores de los cuartiles y los extremos de la variable se generaronÂ cuatro intervalos de descuento:
0â€“31%: Descuentos bajos
31â€“49%: Descuentos moderados
49â€“62%: Descuentos altos
62â€“94%: Descuentos muy altos
ğŸ‘‰ Se creÃ³ una nueva columna llamadaÂ discount_rangeÂ en el DataFrameÂ tabla_union.

ğŸ”¹ AgrupaciÃ³n y CÃ¡lculo de MÃ©tricas
Se agruparon los productos porÂ discount_rangeÂ y se calcularon las siguientes mÃ©tricas por grupo:
NÃºmero de productos distintos
Precio promedio con descuento (discounted_price)
Precio promedio original (actual_price)
Promedio del porcentaje de descuento
Rating promedio

ğŸ“Š Resultados

ğŸ“Œ Conclusiones
A medida que elÂ descuento aumenta, elÂ precio promedio con descuentoÂ disminuye notablemente.
LosÂ productos con mayores descuentos (62â€“94%)Â tienen un precio original alto, pero terminan con precios finales muy bajos.
ElÂ rating promedioÂ se mantiene estable (~4.0â€“4.2) en todos los rangos, lo que sugiere que los consumidores valoran de forma similar los productos independientemente del nivel de descuento.
âœ… Este anÃ¡lisis por rangos facilita la identificaciÃ³n deÂ estrategias de pricingÂ y el comportamiento del mercado frente a diferentes niveles de descuento.

codigo:
q1_discountÂ =Â tabla_union['discount_percentage'].quantile(0.25)
q2_discountÂ =Â tabla_union['discount_percentage'].quantile(0.50)
q3_discountÂ =Â tabla_union['discount_percentage'].quantile(0.75)

print(f"PrimerÂ cuartilÂ (Q1)Â deÂ discount_percentage:Â {q1_discount:.2f}")
print(f"SegundoÂ cuartilÂ (Q2)Â oÂ MedianaÂ deÂ discount_percentage:Â {q2_discount:.2f}")
print(f"TercerÂ cuartilÂ (Q3)Â deÂ discount_percentage:Â {q3_discount:.2f}")

codigo:
```python
#Â DefinaÂ losÂ contenedoresÂ utilizandoÂ losÂ cuartilesÂ calculadosÂ yÂ losÂ valoresÂ mÃ­nimos/mÃ¡ximos
min_discountÂ =Â tabla_union['discount_percentage'].min()
max_discountÂ =Â tabla_union['discount_percentage'].max()

binsÂ =Â [min_discount,Â q1_discount,Â q2_discount,Â q3_discount,Â max_discount]

#Â DefinirÂ lasÂ etiquetasÂ paraÂ losÂ rangos
labelsÂ =Â [f'{min_discount:.0f}-{q1_discount:.0f}',
Â Â Â Â Â Â Â Â Â Â f'{q1_discount:.0f}-{q2_discount:.0f}',
Â Â Â Â Â Â Â Â Â Â f'{q2_discount:.0f}-{q3_discount:.0f}',
Â Â Â Â Â Â Â Â Â Â f'{q3_discount:.0f}-{max_discount:.0f}']

#Â AsegÃºreseÂ deÂ queÂ losÂ contenedoresÂ seanÂ ÃºnicosÂ yÂ estÃ©nÂ ordenadosÂ siÂ hayÂ valoresÂ deÂ cuartilesÂ idÃ©nticosÂ oÂ mÃ­nimos/mÃ¡ximosÂ enÂ losÂ cuartiles
unique_binsÂ =Â sorted(list(set(bins)))

#Â AjusteÂ lasÂ etiquetasÂ siÂ losÂ contenedoresÂ resultaronÂ enÂ menosÂ lÃ­mitesÂ ÃºnicosÂ deÂ loÂ esperado
ifÂ len(unique_bins)Â -Â 1Â !=Â len(labels):
Â Â Â Â #Â UnaÂ formaÂ mÃ¡sÂ robustaÂ deÂ crearÂ etiquetasÂ basadasÂ enÂ contenedoresÂ Ãºnicos
Â Â Â Â labelsÂ =Â [f'{unique_bins[i]:.0f}-{unique_bins[i+1]:.0f}'Â forÂ iÂ inÂ range(len(unique_bins)-1)]
Â Â Â Â print(f"EtiquetasÂ ajustadasÂ debidoÂ aÂ contenedoresÂ noÂ Ãºnicos:Â {labels}")


#Â CreeÂ laÂ columnaÂ 'discount_range'Â usandoÂ pd.cut
tabla_union['discount_range']Â =Â pd.cut(tabla_union['discount_percentage'],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â bins=unique_bins,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â labels=labels,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â include_lowest=True,Â #Â IncluyaÂ elÂ valorÂ mÃ¡sÂ bajoÂ enÂ elÂ primerÂ contenedor
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â right=True)Â #Â LosÂ intervalosÂ sonÂ (abiertos,Â cerrados]Â exceptoÂ elÂ primero


print("âœ…Â NuevaÂ columnaÂ 'discount_range'Â creada.")

#Â MostrarÂ lasÂ primerasÂ filasÂ paraÂ verificarÂ laÂ nuevaÂ columna
print("\nPrimerasÂ filasÂ delÂ DataFrameÂ conÂ laÂ columnaÂ 'discount_range':")
display(tabla_union.head())
```

codigo:
tabla_union_groupedÂ =Â tabla_union.groupby('discount_range')

print("âœ…Â DataFrameÂ 'tabla_union'Â agrupadoÂ porÂ 'discount_range'.")
print("\nElÂ objetoÂ GroupByÂ estÃ¡Â listoÂ paraÂ calcularÂ mÃ©tricasÂ agregadas.")

codigo:
discount_range_metricsÂ =Â tabla_union_grouped.agg(
Â Â Â Â num_productos=('product_id',Â 'nunique'),
Â Â Â Â avg_discounted_price=('discounted_price',Â 'mean'),
Â Â Â Â avg_actual_price=('actual_price',Â 'mean'),
Â Â Â Â avg_discount_percentage=('discount_percentage',Â 'mean'),
Â Â Â Â avg_rating=('rating',Â 'mean')
)

print("âœ…Â MÃ©tricasÂ calculadasÂ paraÂ cadaÂ rangoÂ deÂ descuento.")
print("\nMÃ©tricasÂ porÂ rangoÂ deÂ descuento:")
display(discount_range_metrics)

codigo:
```python
print("MÃ©tricasÂ calculadasÂ porÂ rangoÂ deÂ descuento:")
display(discount_range_metrics)
```

11. AnÃ¡lisis de Variables CategÃ³ricas
ğŸ¯ Objetivo
Analizar variables categÃ³ricas creadas a partir de transformaciones de datos numÃ©ricos, en este caso:
discount_rangeÂ (definido con base en cuartiles).
rating_categoryÂ (definido en intervalos fijos de rating).

ğŸ”¹ Hallazgos Previos
Los cuartiles deÂ discount_percentageÂ fueron:
Q1:Â 31.25
Q2 (Mediana):Â 49.00
Q3:Â 62.00
Estos valores se usaron para crearÂ rangos de descuentoÂ (discount_range), con los que se calcularon mÃ©tricas clave (nÃºmero de productos, precios promedios, descuentos y rating).

ğŸ”¹ AnÃ¡lisis de la VariableÂ rating
Se calcularon los valores bÃ¡sicos de la columnaÂ ratingÂ en todo el dataset:
Valor mÃ¡ximo:Â 5.00
Valor mÃ­nimo:Â 2.00
Valor promedio:Â 4.08
ğŸ“Œ InterpretaciÃ³n: la mayorÃ­a de los productos tienen calificaciones cercanas a 4 estrellas, con pocos casos en los extremos.

ğŸ”¹ CreaciÃ³n de CategorÃ­as de Rating
Para complementar el anÃ¡lisis, se creÃ³ la variable categÃ³ricaÂ rating_categoryÂ con base en intervalos fijos:
Bajo (1â€“3)
Medio (3â€“4)
Alto (4â€“5)

ğŸ“Š Resultados de la CategorizaciÃ³n
Bajo (1â€“3):Â 6 productos
Medio (3â€“4):Â 318 productos
Alto (4â€“5):Â 870 productos
ğŸ‘‰ Esto confirma que la mayorÃ­a de los productos estÃ¡n bien valorados (mÃ¡s del 70% tienen rating â‰¥ 4).

ğŸ”¹ Ejemplo de la Nueva Columna enÂ tabla_union
Las primeras filas muestran la columnaÂ rating_categoryÂ correctamente agregada:

ğŸ“Œ Conclusiones
LaÂ distribuciÃ³n de ratings estÃ¡ sesgada hacia lo alto, lo cual refleja satisfacciÃ³n de los clientes.
Solo una fracciÃ³n mÃ­nima de productos cae en la categorÃ­aÂ Bajo (1â€“3).
La combinaciÃ³n de variables categÃ³ricas (discount_rangeÂ +Â rating_category) permitirÃ¡ mÃ¡s adelante analizar si existe relaciÃ³n entreÂ descuentos aplicados y valoraciones de clientes.

codigo:
```python
#Â CalcularÂ elÂ valorÂ mÃ¡ximo,Â mÃ­nimoÂ yÂ promedioÂ deÂ laÂ columnaÂ 'rating'Â enÂ tabla_union
max_ratingÂ =Â tabla_union['rating'].max()
min_ratingÂ =Â tabla_union['rating'].min()
mean_ratingÂ =Â tabla_union['rating'].mean()

print(f"ValorÂ mÃ¡ximoÂ deÂ Rating:Â {max_rating:.2f}")
print(f"ValorÂ mÃ­nimoÂ deÂ Rating:Â {min_rating:.2f}")
print(f"ValorÂ promedioÂ deÂ Rating:Â {mean_rating:.2f}")
```

codigo:
```python
importÂ pandasÂ asÂ pd

#Â DefinirÂ losÂ lÃ­mitesÂ deÂ losÂ rangosÂ deÂ ratingÂ paraÂ elÂ EjemploÂ 1
#Â AseguramosÂ queÂ elÂ lÃ­miteÂ superiorÂ incluyeÂ elÂ 5.0
bins_ratingÂ =Â [1,Â 3,Â 4,Â 5.1]

#Â DefinirÂ lasÂ etiquetasÂ paraÂ losÂ rangos
labels_ratingÂ =Â ['BajoÂ (1-3)',Â 'MedioÂ (3-4)',Â 'AltoÂ (4-5)']

#Â CrearÂ laÂ nuevaÂ columnaÂ 'rating_category'Â enÂ tabla_union
tabla_union['rating_category']Â =Â pd.cut(tabla_union['rating'],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â bins=bins_rating,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â labels=labels_rating,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â include_lowest=True,Â #Â IncluirÂ elÂ valorÂ mÃ¡sÂ bajoÂ (1)Â enÂ elÂ primerÂ bin
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â right=False)Â #Â LosÂ intervalosÂ sonÂ [inicio,Â fin)Â exceptoÂ elÂ Ãºltimo

#Â MostrarÂ losÂ conteosÂ porÂ categorÃ­a
print("ConteoÂ deÂ registrosÂ porÂ categorÃ­aÂ deÂ RatingÂ (RangosÂ Fijos):")
display(tabla_union['rating_category'].value_counts().sort_index())

#Â MostrarÂ lasÂ primerasÂ filasÂ conÂ laÂ nuevaÂ columna
print("\nPrimerasÂ filasÂ delÂ DataFrameÂ conÂ laÂ nuevaÂ columnaÂ 'rating_category':")
display(tabla_union.head())
```

codigo:
```python
#Â GuardarÂ elÂ DataFrameÂ tabla_unionÂ aÂ unÂ archivoÂ CSV
tabla_union.to_csv("tablaÂ union.csv",Â index=False)

print("âœ…Â DataFrameÂ 'tabla_union'Â guardadoÂ exitosamenteÂ comoÂ 'tablaÂ union.csv'")
```

codigo:
```python
#Â MostrarÂ elÂ encabezadoÂ deÂ laÂ tabla_union
print("EncabezadoÂ deÂ laÂ tabla_union:")
display(tabla_union.head())
```

12. Medidas de Tendencia Central y DispersiÃ³n
ğŸ¯ Objetivo
Calcular estadÃ­sticas descriptivas bÃ¡sicas de las variables numÃ©ricas mÃ¡s relevantes del DataFrameÂ tabla_union, con el fin de entender su distribuciÃ³n y variabilidad.
ğŸ”¹ Variables Analizadas
discounted_price
actual_price
discount_percentage
rating
rating_count
ğŸ”¹ Medidas Calculadas
Para cada variable se calcularon las siguientes mÃ©tricas:
Media (Promedio)
Mediana (Percentil 50)
Moda (valor mÃ¡s frecuente)
DesviaciÃ³n EstÃ¡ndar

codigo:
```python
#Â DefinirÂ lasÂ columnasÂ numÃ©ricasÂ deÂ interÃ©s
columnas_numericasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']

#Â CrearÂ unÂ diccionarioÂ paraÂ almacenarÂ losÂ resultados
metricas_numericasÂ =Â {}

#Â CalcularÂ lasÂ mÃ©tricasÂ paraÂ cadaÂ columna
forÂ colÂ inÂ columnas_numericas:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â mean_valÂ =Â tabla_union[col].mean()
Â Â Â Â Â Â Â Â median_valÂ =Â tabla_union[col].median()
Â Â Â Â Â Â Â Â #Â ModaÂ puedeÂ devolverÂ mÃºltiplesÂ valores,Â tomamosÂ elÂ primeroÂ siÂ existe
Â Â Â Â Â Â Â Â mode_valÂ =Â tabla_union[col].mode().tolist()Â ifÂ notÂ tabla_union[col].mode().emptyÂ elseÂ None
Â Â Â Â Â Â Â Â std_valÂ =Â tabla_union[col].std()

Â Â Â Â Â Â Â Â metricas_numericas[col]Â =Â {
Â Â Â Â Â Â Â Â Â Â Â Â 'Media':Â mean_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'Mediana':Â median_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'Moda':Â mode_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'DesviaciÃ³nÂ EstÃ¡ndar':Â std_val
Â Â Â Â Â Â Â Â }
Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"âš ï¸Â Advertencia:Â LaÂ columnaÂ '{col}'Â noÂ seÂ encontrÃ³Â enÂ laÂ tabla_union.")

#Â ConvertirÂ elÂ diccionarioÂ aÂ unÂ DataFrameÂ paraÂ unaÂ mejorÂ visualizaciÃ³n
df_metricasÂ =Â pd.DataFrame(metricas_numericas).TÂ #Â TransponemosÂ paraÂ queÂ lasÂ columnasÂ seanÂ lasÂ variables

print("ğŸ“ŠÂ MedidasÂ deÂ TendenciaÂ CentralÂ yÂ DispersiÃ³nÂ paraÂ VariablesÂ NumÃ©ricas:")
display(df_metricas)
```

InterpretaciÃ³n de los Resultados:
Como experto en anÃ¡lisis de datos, aquÃ­ estÃ¡ mi interpretaciÃ³n de las mÃ©tricas calculadas:
discounted_priceÂ yÂ actual_price:
LaÂ MediaÂ es significativamente mÃ¡s alta que laÂ MedianaÂ para ambas columnas. Esto sugiere que la distribuciÃ³n de los precios (tanto con descuento como real) estÃ¡Â sesgada positivamente (hacia la derecha). Hay una "cola" de productos con precios mÃ¡s altos que elevan la media por encima del valor central (mediana).
LaÂ ModaÂ paraÂ discounted_priceÂ yÂ actual_priceÂ indica los precios mÃ¡s frecuentes. ParaÂ discounted_price, el precio mÃ¡s comÃºn es 199.0, mientras que paraÂ actual_priceÂ es 999.0. Esto sugiere que hay una gran cantidad de productos de menor precio en el dataset.
LaÂ DesviaciÃ³n EstÃ¡ndarÂ es relativamente alta para ambas columnas (especialmenteÂ actual_price), lo que confirma unaÂ alta variabilidadÂ en los precios de los productos. Esto es esperado en un catÃ¡logo diverso de comercio electrÃ³nico.
discount_percentage:
LaÂ MediaÂ (aprox. 49.8%) y laÂ MedianaÂ (49.0%) son bastante cercanas. Esto sugiere que la distribuciÃ³n de los porcentajes de descuento esÂ relativamente simÃ©tricaÂ alrededor del centro, aunque puede haber un ligero sesgo.
LaÂ ModaÂ en 50.0% indica que un descuento del 50% es el mÃ¡s frecuente en este dataset.
LaÂ DesviaciÃ³n EstÃ¡ndarÂ (aprox. 21.2%) muestra una dispersiÃ³n moderada en los porcentajes de descuento. Hay una variedad razonable de descuentos aplicados a travÃ©s de los productos.
rating:
LaÂ MediaÂ (aprox. 4.08),Â MedianaÂ (4.20) yÂ ModaÂ (4.10) estÃ¡n muy juntas y son valores altos (cercanos a 4 y 5 en una escala de 1 a 5). Esto indica que la distribuciÃ³n de los ratings estÃ¡Â fuertemente sesgada negativamente (hacia la izquierda), concentrÃ¡ndose en las calificaciones altas. La mayorÃ­a de los productos reciben ratings positivos.
LaÂ DesviaciÃ³n EstÃ¡ndarÂ (aprox. 0.37) es baja, lo que confirma que los ratings estÃ¡n muy agrupados alrededor de la media/mediana alta. Hay poca variabilidad en las calificaciones (la mayorÃ­a son buenas).
rating_count:
LaÂ MediaÂ (aprox. 22400) es drÃ¡sticamente mayor que laÂ MedianaÂ (4118.0). Esto es un claro indicador de una distribuciÃ³nÂ altamente sesgada positivamente (hacia la derecha). La mayorÃ­a de los productos tienen un nÃºmero de reseÃ±as relativamente bajo, pero hay una minorÃ­a de productos extremadamente populares con un nÃºmero de reseÃ±as muy alto que inflan la media.
LaÂ ModaÂ (2) sugiere que el nÃºmero mÃ¡s frecuente de reseÃ±as para un producto es muy bajo.
LaÂ DesviaciÃ³n EstÃ¡ndarÂ (aprox. 54300) es muy alta, lo que resalta laÂ enorme variabilidadÂ en el nÃºmero de reseÃ±as entre productos. Esta es la variable con mayor dispersiÃ³n relativa, confirmando la presencia de "best-sellers" con muchÃ­simas reseÃ±as.
ConclusiÃ³n:
El anÃ¡lisis de estas mÃ©tricas confirma la naturaleza tÃ­pica de los datos de comercio electrÃ³nico: precios con cierto sesgo hacia arriba, una distribuciÃ³n de descuentos mÃ¡s centrada, ratings predominantemente altos y un conteo de reseÃ±as muy asimÃ©trico, con pocos productos concentrando la mayorÃ­a de las interacciones de los usuarios. Estas observaciones son cruciales para decidir quÃ© anÃ¡lisis son apropiados y cÃ³mo manejar posibles outliers o transformaciones para modelado.

13. VisualizaciÃ³n de la DistribuciÃ³n de Variables NumÃ©ricas
ğŸ¯ Objetivo
Analizar grÃ¡ficamente la distribuciÃ³n de las principales variables numÃ©ricas del DataFrameÂ tabla_union, para identificar sesgos, concentraciones de valores y posibles outliers.
ğŸ”¹ Variables Consideradas
discounted_price
actual_price
discount_percentage
rating
rating_count

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â DefinirÂ lasÂ columnasÂ numÃ©ricasÂ paraÂ visualizar
columnas_numericasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']

#Â ConfigurarÂ elÂ estiloÂ deÂ losÂ grÃ¡ficos
sns.set_style("whitegrid")

#Â CrearÂ unÂ histogramaÂ paraÂ cadaÂ columna
forÂ colÂ inÂ columnas_numericas:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â plt.figure(figsize=(10,Â 6))Â #Â TamaÃ±oÂ delÂ grÃ¡fico
Â Â Â Â Â Â Â Â sns.histplot(data=tabla_union,Â x=col,Â kde=True)Â #Â kde=TrueÂ aÃ±adeÂ laÂ curvaÂ deÂ densidadÂ estimada
Â Â Â Â Â Â Â Â plt.title(f'DistribuciÃ³nÂ deÂ {col}')
Â Â Â Â Â Â Â Â plt.xlabel(col)
Â Â Â Â Â Â Â Â plt.ylabel('Frecuencia')
Â Â Â Â Â Â Â Â plt.show()
Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"âš ï¸Â Advertencia:Â LaÂ columnaÂ '{col}'Â noÂ seÂ encontrÃ³Â enÂ laÂ tabla_union,Â noÂ seÂ puedeÂ crearÂ elÂ histograma.")
```

InterpretaciÃ³n de las Distribuciones (Basado en los Histogramas):
Una vez ejecutado el cÃ³digo anterior y visualizados los histogramas, aquÃ­ tienes una interpretaciÃ³n general de los tipos de distribuciÃ³n que probablemente observarÃ¡s para cada variable:
discounted_price:
Tipo de DistribuciÃ³n:Â ProbablementeÂ sesgada a la derecha (positivamente). La mayorÃ­a de los productos se concentrarÃ¡n en precios mÃ¡s bajos, con una "cola" larga extendiÃ©ndose hacia precios mÃ¡s altos. Esto es comÃºn en datos de precios, donde hay muchos artÃ­culos de precio bajo a medio y menos artÃ­culos de precio muy alto.
actual_price:
Tipo de DistribuciÃ³n:Â Similar aÂ discounted_price, es muy probable que estÃ©Â sesgada a la derecha (positivamente). La diferencia entre el precio real y el de descuento no cambia fundamentalmente la forma general de la distribuciÃ³n de precios, aunque la dispersiÃ³n podrÃ­a ser ligeramente diferente. La mayorÃ­a de los productos tendrÃ¡n precios reales mÃ¡s bajos.
discount_percentage:
Tipo de DistribuciÃ³n:Â PodrÃ­a serÂ aproximadamente simÃ©tricaÂ o tener un ligero sesgo, pero probablemente no tan pronunciado como las variables de precio. Nuestros cÃ¡lculos de medidas de tendencia central ya sugerÃ­an una distribuciÃ³n mÃ¡s centrada. Es posible que veas picos en porcentajes de descuento comunes (como 10%, 20%, 50%, etc.).
rating:
Tipo de DistribuciÃ³n:Â FuertementeÂ sesgada a la izquierda (negativamente). La gran mayorÃ­a de los ratings se concentrarÃ¡n en los valores mÃ¡s altos (4, 5), con una "cola" mÃ¡s pequeÃ±a hacia los ratings mÃ¡s bajos (1, 2, 3). Esto es muy tÃ­pico en reseÃ±as de productos, donde los clientes satisfechos tienden a dejar ratings altos.
rating_count:
Tipo de DistribuciÃ³n:Â AltamenteÂ sesgada a la derecha (positivamente). VerÃ¡s un gran pico en los valores bajos (productos con pocas reseÃ±as) y una "cola" extremadamente larga hacia la derecha, representando esa minorÃ­a de productos muy populares con miles o decenas de miles de reseÃ±as. Esta es una de las distribuciones mÃ¡s asimÃ©tricas en conjuntos de datos de este tipo.
Consideraciones:
La curva KDE (EstimaciÃ³n de Densidad del Kernel) en los histogramas te darÃ¡ una idea suavizada de la forma de la distribuciÃ³n.
La forma exacta puede variar ligeramente dependiendo de cÃ³mo se generen los "bins" del histograma, pero el patrÃ³n general de sesgo deberÃ­a ser claro.

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â DefinirÂ lasÂ columnasÂ numÃ©ricasÂ paraÂ visualizar
columnas_numericasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']

#Â ConfigurarÂ elÂ estiloÂ deÂ losÂ grÃ¡ficos
sns.set_style("whitegrid")

#Â CrearÂ unÂ grÃ¡ficoÂ deÂ densidadÂ paraÂ cadaÂ columna
forÂ colÂ inÂ columnas_numericas:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â plt.figure(figsize=(10,Â 6))Â #Â TamaÃ±oÂ delÂ grÃ¡fico
Â Â Â Â Â Â Â Â sns.kdeplot(data=tabla_union,Â x=col,Â fill=True)Â #Â fill=TrueÂ rellenaÂ elÂ Ã¡reaÂ bajoÂ laÂ curva
Â Â Â Â Â Â Â Â plt.title(f'GrÃ¡ficoÂ deÂ DensidadÂ deÂ {col}')
Â Â Â Â Â Â Â Â plt.xlabel(col)
Â Â Â Â Â Â Â Â plt.ylabel('Densidad')
Â Â Â Â Â Â Â Â plt.show()
Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"âš ï¸Â Advertencia:Â LaÂ columnaÂ '{col}'Â noÂ seÂ encontrÃ³Â enÂ laÂ tabla_union,Â noÂ seÂ puedeÂ crearÂ elÂ grÃ¡ficoÂ deÂ densidad.")
```

InterpretaciÃ³n de la SimetrÃ­a/AsimetrÃ­a (Basado en los GrÃ¡ficos de Densidad):
Observando los grÃ¡ficos de densidad (curvas KDE) que hemos generado (y que tambiÃ©n se mostraban sobre los histogramas):
discounted_price:
SimetrÃ­a:Â AsimÃ©trica positiva (sesgada a la derecha). La cola de la distribuciÃ³n se extiende mucho mÃ¡s hacia los valores altos que hacia los bajos. Esto indica que hay una concentraciÃ³n de productos con precios de descuento bajos, y menos productos con precios de descuento altos.
actual_price:
SimetrÃ­a:Â AsimÃ©trica positiva (sesgada a la derecha). Similar aÂ discounted_price, la curva de densidad muestra una cola larga hacia los valores de precio real altos. La mayorÃ­a de los productos tienen precios reales bajos.
discount_percentage:
SimetrÃ­a:Â Aproximadamente simÃ©trica, aunque puede tener ligeras irregularidades o mÃºltiples picos pequeÃ±os. La curva de densidad no muestra una cola larga y pronunciada hacia un lado en particular, sugiriendo que los porcentajes de descuento se distribuyen de manera mÃ¡s equilibrada alrededor de su media/mediana.
rating:
SimetrÃ­a:Â AsimÃ©trica negativa (sesgada a la izquierda). La mayor parte de la masa de la distribuciÃ³n se encuentra en los valores altos, con una cola que se extiende hacia los valores bajos. Esto refleja que la mayorÃ­a de los productos reciben calificaciones altas.
rating_count:
SimetrÃ­a:Â Altamente asimÃ©trica positiva (sesgada a la derecha). La curva de densidad tiene un pico muy alto cerca de cero y una cola extremadamente larga y plana que se extiende hacia los valores muy altos. Esto subraya la gran disparidad en el nÃºmero de reseÃ±as, con la mayorÃ­a de los productos teniendo muy pocas y un pequeÃ±o nÃºmero teniendo muchÃ­simas.
ConclusiÃ³n sobre la SimetrÃ­a:
Las variables de precio yÂ rating_countÂ presentan una asimetrÃ­a marcada, lo cual es tÃ­pico en datos de ventas y popularidad. La variableÂ ratingÂ tambiÃ©n es asimÃ©trica, pero hacia el lado de las calificaciones altas. SoloÂ discount_percentageÂ muestra una distribuciÃ³n mÃ¡s cercana a la simetrÃ­a. Reconocer esta asimetrÃ­a es importante para elegir mÃ©todos de anÃ¡lisis adecuados o considerar transformaciones si es necesario.

14. Calcular medidas de dispersiÃ³n

codigo:
```python
#Â DefinirÂ lasÂ columnasÂ numÃ©ricasÂ deÂ interÃ©s
columnas_numericasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']

#Â CrearÂ unÂ diccionarioÂ paraÂ almacenarÂ losÂ resultados
medidas_dispersionÂ =Â {}

#Â CalcularÂ laÂ varianzaÂ yÂ elÂ IQRÂ paraÂ cadaÂ columna
forÂ colÂ inÂ columnas_numericas:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â varianza_valÂ =Â tabla_union[col].var()
Â Â Â Â Â Â Â Â q1Â =Â tabla_union[col].quantile(0.25)
Â Â Â Â Â Â Â Â q3Â =Â tabla_union[col].quantile(0.75)
Â Â Â Â Â Â Â Â iqr_valÂ =Â q3Â -Â q1

Â Â Â Â Â Â Â Â medidas_dispersion[col]Â =Â {
Â Â Â Â Â Â Â Â Â Â Â Â 'Varianza':Â varianza_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'RangoÂ IntercuartÃ­licoÂ (IQR)':Â iqr_val
Â Â Â Â Â Â Â Â }
Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"âš ï¸Â Advertencia:Â LaÂ columnaÂ '{col}'Â noÂ seÂ encontrÃ³Â enÂ laÂ tabla_union.")

#Â ConvertirÂ elÂ diccionarioÂ aÂ unÂ DataFrameÂ paraÂ unaÂ mejorÂ visualizaciÃ³n
df_dispersionÂ =Â pd.DataFrame(medidas_dispersion).TÂ #Â TransponemosÂ paraÂ queÂ lasÂ columnasÂ seanÂ lasÂ variables

print("ğŸ“ŠÂ MedidasÂ deÂ DispersiÃ³nÂ paraÂ VariablesÂ NumÃ©ricas:")
display(df_dispersion)
```

ExplicaciÃ³n de las Medidas de DispersiÃ³n:
Varianza:
QuÃ© describe:Â La varianza mide cuÃ¡nto se dispersan los valores individuales con respecto a la media. Un valor de varianza alto indica que los puntos de datos estÃ¡n muy alejados de la media y entre sÃ­ (alta dispersiÃ³n), mientras que un valor bajo indica que los puntos de datos estÃ¡n agrupados cerca de la media (baja dispersiÃ³n).
InterpretaciÃ³n en tus datos:
discounted_priceÂ yÂ actual_priceÂ tienen valores de varianza muy altos, lo que confirma lo que vimos en los histogramas y la desviaciÃ³n estÃ¡ndar: hay una gran variabilidad en los precios. Esto es de esperar en un catÃ¡logo de productos diverso.
discount_percentageÂ tiene una varianza menor en comparaciÃ³n con los precios, lo que sugiere que los porcentajes de descuento estÃ¡n menos dispersos que los precios reales.
ratingÂ tiene una varianza muy baja, lo que indica que los ratings estÃ¡n muy concentrados alrededor de la media (entre 4 y 5), confirmando la poca variabilidad y el sesgo hacia ratings altos.
rating_countÂ tiene una varianza extremadamente alta, lo que resalta la enorme dispersiÃ³n en el nÃºmero de reseÃ±as. Esto se debe a la presencia de productos con un nÃºmero de reseÃ±as drÃ¡sticamente mayor que la mayorÃ­a.
Rango IntercuartÃ­lico (IQR):
QuÃ© describe:Â El IQR es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Representa el rango en el que se encuentra el 50% central de los datos. Es una medida de dispersiÃ³nÂ robusta a los outliers, ya que no se ve afectada por los valores extremos en las colas de la distribuciÃ³n. Un IQR grande indica que el 50% central de los datos estÃ¡ muy disperso, mientras que un IQR pequeÃ±o indica que estÃ¡n mÃ¡s agrupados.
InterpretaciÃ³n en tus datos:
discounted_priceÂ yÂ actual_priceÂ tienen IQRs considerablemente grandes (comparados con su escala), lo que indica que el 50% central de los precios tiene un rango amplio.
discount_percentageÂ tiene un IQR que muestra el rango del 50% central de los descuentos.
ratingÂ tiene un IQR muy pequeÃ±o. Esto refuerza que el 50% central de los ratings estÃ¡ muy agrupado (entre 3.9 y 4.2 aproximadamente, basÃ¡ndonos en Q1 y Q3 de turnos anteriores), confirmando nuevamente la poca variabilidad en la parte central de la distribuciÃ³n de ratings.
rating_countÂ tiene un IQR que, aunque no tan alto como la varianza, sigue siendo significativo, mostrando el rango del 50% central de los conteos de reseÃ±as. Sin embargo, la gran diferencia entre la varianza (muy afectada por los extremos) y el IQR (robusto a extremos) paraÂ rating_countÂ es una seÃ±al clara de la asimetrÃ­a y la presencia de outliers.
En resumen, tanto la varianza como el IQR nos dan una idea de la dispersiÃ³n de los datos, pero el IQR es especialmente Ãºtil para entender la variabilidad en la parte central de la distribuciÃ³n y es menos sensible a la influencia de los valores atÃ­picos extremos.

15. Calcular correlaciones

codigo:
```python
#Â DefinirÂ lasÂ columnasÂ numÃ©ricasÂ paraÂ calcularÂ laÂ correlaciÃ³n
columnas_numericasÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']

#Â CalcularÂ laÂ matrizÂ deÂ correlaciÃ³nÂ deÂ Pearson
#Â AsegurarseÂ deÂ queÂ lasÂ columnasÂ existenÂ antesÂ deÂ seleccionarlas
columnas_existentesÂ =Â [colÂ forÂ colÂ inÂ columnas_numericasÂ ifÂ colÂ inÂ tabla_union.columns]

ifÂ len(columnas_existentes)Â >Â 1:
Â Â Â Â correlacion_pearsonÂ =Â tabla_union[columnas_existentes].corr(method='pearson')

Â Â Â Â print("ğŸ“ŠÂ MatrizÂ deÂ CorrelaciÃ³nÂ deÂ Pearson:")
Â Â Â Â display(correlacion_pearson)
else:
Â Â Â Â print("âš ï¸Â NoÂ hayÂ suficientesÂ columnasÂ numÃ©ricasÂ existentesÂ paraÂ calcularÂ laÂ correlaciÃ³n.")
Â Â Â Â print(f"ColumnasÂ encontradas:Â {columnas_existentes}")
```

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â AsegurarseÂ deÂ queÂ laÂ matrizÂ deÂ correlaciÃ³nÂ existe
ifÂ 'correlacion_pearson'Â inÂ globals()Â andÂ isinstance(globals()['correlacion_pearson'],Â pd.DataFrame):
Â Â Â Â print("ğŸ“ŠÂ MapaÂ deÂ CalorÂ deÂ laÂ MatrizÂ deÂ CorrelaciÃ³n:")

Â Â Â Â plt.figure(figsize=(10,Â 8))Â #Â TamaÃ±oÂ delÂ grÃ¡fico
Â Â Â Â sns.heatmap(correlacion_pearson,Â annot=True,Â cmap='coolwarm',Â fmt=".2f",Â linewidths=.5)
Â Â Â Â plt.title('MapaÂ deÂ CalorÂ deÂ laÂ MatrizÂ deÂ CorrelaciÃ³nÂ deÂ Pearson')
Â Â Â Â plt.show()
else:
Â Â Â Â print("âš ï¸Â LaÂ matrizÂ deÂ correlaciÃ³nÂ deÂ PearsonÂ noÂ seÂ encontrÃ³.Â PorÂ favor,Â calculaÂ laÂ matrizÂ primero.")
```

InterpretaciÃ³n del Mapa de Calor de CorrelaciÃ³n:
Una vez que veas el mapa de calor generado, aquÃ­ tienes una interpretaciÃ³n de las relaciones entre las variables numÃ©ricas:
Colores:
Los colores cÃ¡lidos (rojo/naranja) indican unaÂ correlaciÃ³n positiva. Cuanto mÃ¡s intenso el color, mÃ¡s fuerte es la relaciÃ³n positiva.
Los colores frÃ­os (azul/morado) indican unaÂ correlaciÃ³n negativa. Cuanto mÃ¡s intenso el color, mÃ¡s fuerte es la relaciÃ³n negativa.
Los colores cercanos al blanco o gris indican unaÂ correlaciÃ³n cercana a ceroÂ (poca o ninguna relaciÃ³n lineal).
Valores (annot=True):Â Los nÃºmeros dentro de cada celda son los coeficientes de correlaciÃ³n de Pearson.
Interpretaciones Clave (basadas en la matriz calculada anteriormente):
discounted_priceÂ vsÂ actual_price:Â DeberÃ­as ver un color cÃ¡lido muy intenso (coeficiente cercano a +1). Esto es lÃ³gico, ya que el precio con descuento estÃ¡ directamente relacionado con el precio original. Los productos con precios originales altos tienden a tener precios con descuento altos, y viceversa.
discount_percentageÂ vsÂ discounted_priceÂ /Â actual_price:Â DeberÃ­as observar colores frÃ­os (correlaciÃ³n negativa), probablemente de intensidad baja a moderada. Esto significa que, en general, a medida que aumenta el porcentaje de descuento, los precios (tanto el original como el de descuento) tienden a serÂ menores. Sin embargo, la correlaciÃ³n no es muy fuerte, lo que sugiere que no solo los productos baratos tienen grandes descuentos, sino que tambiÃ©n puede haber productos caros con descuentos significativos (o viceversa), lo cual es realista en el comercio electrÃ³nico.
ratingÂ vsÂ discount_percentage:Â Es probable que veas una correlaciÃ³n negativa baja (color frÃ­o pÃ¡lido). Esto sugerirÃ­a que los productos con mayores descuentos tienden a tener ratings ligeramente mÃ¡s bajos, o que los productos con ratings mÃ¡s altos tienden a tener menores descuentos. Sin embargo, la relaciÃ³n lineal es dÃ©bil.
ratingÂ vsÂ discounted_priceÂ /Â actual_price:Â DeberÃ­as ver correlaciones positivas muy bajas o cercanas a cero (colores muy pÃ¡lidos o blancos/grises). Esto indica que no hay una relaciÃ³n lineal fuerte entre el precio de un producto y su calificaciÃ³n promedio. Los productos caros no necesariamente tienen mejores ratings que los baratos, ni viceversa.
ratingÂ vsÂ rating_count:Â Es probable que veas una correlaciÃ³n positiva baja (color cÃ¡lido pÃ¡lido). Esto podrÃ­a sugerir que los productos con mÃ¡s reseÃ±as tienden a tener ratings ligeramente mÃ¡s altos, pero la relaciÃ³n lineal no es fuerte. Otros factores influyen mÃ¡s en el rating.
rating_countÂ vsÂ discounted_priceÂ /Â actual_price:Â DeberÃ­as ver correlaciones muy cercanas a cero o negativas muy dÃ©biles. Esto indica que no hay una relaciÃ³n lineal fuerte entre el precio de un producto y el nÃºmero de reseÃ±as que recibe. Los productos mÃ¡s caros no necesariamente tienen mÃ¡s o menos reseÃ±as que los productos mÃ¡s baratos.
En resumen:Â El mapa de calor te confirmarÃ¡ las relaciones obvias (precios entre sÃ­) y te mostrarÃ¡ que las relaciones lineales entre descuento, rating y conteo de reseÃ±as son generalmente dÃ©biles en este dataset. Esto no significa que no existan otras formas de relaciÃ³n (no lineales) o que no haya patrones al analizar por categorÃ­as, pero linealmente, no hay dependencias fuertes entre estas variables.

AnÃ¡lisis de la Pregunta de Negocio: Â¿Los productos con mayores descuentos tienen mejores calificaciones?
Para responder a esta pregunta, nos centraremos en la relaciÃ³n entre el porcentaje de descuento aplicado a un producto y su calificaciÃ³n promedio recibida por los usuarios.
Variables Relevantes:
discount_percentage: El porcentaje de descuento ofrecido.
rating: La calificaciÃ³n promedio del producto.
AnÃ¡lisis de Sustento:
Para entender esta relaciÃ³n, agrupamos los productos por rangos de porcentaje de descuento. Utilizamos los rangos definidos previamente basados en los cuartiles deÂ discount_percentageÂ (0-31%, 31-49%, 49-62%, 62-94%). Luego, calculamos el rating promedio (rating) para todos los productos que caen dentro de cada uno de estos rangos.
La tabla a continuaciÃ³n muestra el rating promedio para cada rango de porcentaje de descuento:

codigo:
```python
#Â MostrarÂ laÂ tablaÂ deÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuentoÂ (calculadaÂ previamente)
#Â AsegurarseÂ deÂ queÂ laÂ tablaÂ deÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuentoÂ existe
ifÂ 'discount_range_metrics'Â inÂ globals()Â andÂ isinstance(globals()['discount_range_metrics'],Â pd.DataFrame):
Â Â Â Â print("ğŸ“ŠÂ RatingÂ PromedioÂ porÂ RangoÂ deÂ PorcentajeÂ deÂ Descuento:")
Â Â Â Â display(discount_range_metrics[['avg_discount_percentage',Â 'avg_rating']])
else:
Â Â Â Â print("âš ï¸Â LaÂ tablaÂ 'discount_range_metrics'Â noÂ seÂ encontrÃ³.Â PorÂ favor,Â asegÃºrateÂ deÂ haberÂ calculadoÂ lasÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuentoÂ primero.")
```

VisualizaciÃ³n:
Para visualizar esta relaciÃ³n de manera clara, generamos un grÃ¡fico de barras que muestra el rating promedio para cada rango de porcentaje de descuento:

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â AsegurarseÂ deÂ queÂ laÂ tablaÂ deÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuentoÂ existe
ifÂ 'discount_range_metrics'Â inÂ globals()Â andÂ isinstance(globals()['discount_range_metrics'],Â pd.DataFrame):
Â Â Â Â print("ğŸ“ŠÂ GrÃ¡ficoÂ deÂ RatingÂ PromedioÂ porÂ RangoÂ deÂ Descuento:")

Â Â Â Â plt.figure(figsize=(10,Â 6))Â #Â TamaÃ±oÂ delÂ grÃ¡fico
Â Â Â Â sns.barplot(x=discount_range_metrics.index,Â y='avg_rating',Â data=discount_range_metrics,Â palette='viridis')
Â Â Â Â plt.title('RatingÂ PromedioÂ porÂ RangoÂ deÂ PorcentajeÂ deÂ Descuento')
Â Â Â Â plt.xlabel('RangoÂ deÂ PorcentajeÂ deÂ Descuento')
Â Â Â Â plt.ylabel('RatingÂ Promedio')
Â Â Â Â plt.ylim(0,Â 5)Â #Â EstablecerÂ elÂ lÃ­miteÂ delÂ ejeÂ yÂ deÂ 0Â aÂ 5Â (escalaÂ deÂ rating)
Â Â Â Â plt.xticks(rotation=0)Â #Â RotarÂ etiquetasÂ delÂ ejeÂ xÂ siÂ sonÂ largas
Â Â Â Â plt.tight_layout()Â #Â AjustarÂ elÂ diseÃ±oÂ paraÂ evitarÂ queÂ lasÂ etiquetasÂ seÂ solapen
Â Â Â Â plt.show()

else:
Â Â Â Â print("âš ï¸Â LaÂ tablaÂ 'discount_range_metrics'Â noÂ seÂ encontrÃ³.Â PorÂ favor,Â asegÃºrateÂ deÂ haberÂ calculadoÂ lasÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuentoÂ primero.")
```

InterpretaciÃ³n de los Resultados y Respuesta a la Pregunta de Negocio:
Observando tanto la tabla de mÃ©tricas como el grÃ¡fico de barras:
El rango de descuento mÃ¡s bajo (0-31%) presenta el rating promedio mÃ¡s alto.
A medida que los rangos de descuento aumentan, el rating promedio tiende a disminuir ligeramente.
Las diferencias en los ratings promedio entre los rangos son relativamente pequeÃ±as, ya que todos los ratings promedio estÃ¡n por encima de 4.0.
Respuesta Final:
Basado en el anÃ¡lisis de los datos de la tablaÂ tabla_union,Â los productos con mayores porcentajes de descuento generalmente NO tienen mejores calificaciones promedio. De hecho, se observa una ligera tendencia a que los productos con menores descuentos tengan calificaciones promedio marginalmente mÃ¡s altas. Esto sugiere que el porcentaje de descuento no es el factor principal que impulsa un rating alto en este conjunto de datos.

AnÃ¡lisis de la RelaciÃ³n entre Precio y Rating
Objetivo
Responder a la pregunta de negocio:
Â¿Existe relaciÃ³n entre el precio de un producto y su rating promedio?
AnÃ¡lisis
Se realizaron dos anÃ¡lisis principales:
VisualizaciÃ³nÂ mediante diagramas de dispersiÃ³n (scatter plots) entre:
Precio con Descuento (discounted_price) y Rating (rating).
Precio Real (actual_price) y Rating (rating). Ambos grÃ¡ficos fueron representados en escala logarÃ­tmica para los precios, con lÃ­neas de tendencia ajustadas.
CÃ¡lculo de Correlaciones:
CorrelaciÃ³n Precio con Descuento vs Rating:Â 0.121
CorrelaciÃ³n Precio Real vs Rating:Â 0.118

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â ===============================
#Â RelaciÃ³nÂ entreÂ PrecioÂ conÂ DescuentoÂ yÂ Rating
#Â ===============================
plt.figure(figsize=(10,Â 6))
sns.regplot(
Â Â Â Â data=tabla_union,
Â Â Â Â x='discounted_price',
Â Â Â Â y='rating',
Â Â Â Â scatter_kws={'alpha':Â 0.4},Â Â Â #Â transparenciaÂ enÂ puntos
Â Â Â Â line_kws={'color':Â 'red'}Â Â Â Â Â #Â lÃ­neaÂ deÂ tendenciaÂ enÂ rojo
)
plt.xscale("log")Â Â #Â EscalaÂ logarÃ­tmicaÂ paraÂ precios
plt.title('RelaciÃ³nÂ entreÂ PrecioÂ conÂ DescuentoÂ yÂ RatingÂ Promedio')
plt.xlabel('PrecioÂ conÂ DescuentoÂ (escalaÂ log)')
plt.ylabel('RatingÂ Promedio')
plt.ylim(0,Â 5.1)
plt.grid(True)
plt.show()

#Â ===============================
#Â RelaciÃ³nÂ entreÂ PrecioÂ RealÂ yÂ Rating
#Â ===============================
plt.figure(figsize=(10,Â 6))
sns.regplot(
Â Â Â Â data=tabla_union,
Â Â Â Â x='actual_price',
Â Â Â Â y='rating',
Â Â Â Â scatter_kws={'alpha':Â 0.4},
Â Â Â Â line_kws={'color':Â 'red'}
)
plt.xscale("log")
plt.title('RelaciÃ³nÂ entreÂ PrecioÂ RealÂ yÂ RatingÂ Promedio')
plt.xlabel('PrecioÂ RealÂ (escalaÂ log)')
plt.ylabel('RatingÂ Promedio')
plt.ylim(0,Â 5.1)
plt.grid(True)
plt.show()

#Â ===============================
#Â CÃ¡lculoÂ deÂ correlaciones
#Â ===============================
corr_discountÂ =Â tabla_union['discounted_price'].corr(tabla_union['rating'])
corr_actualÂ =Â tabla_union['actual_price'].corr(tabla_union['rating'])

print("ğŸ“ŠÂ CorrelacionesÂ entreÂ precioÂ yÂ rating:")
print(f"Â -Â CorrelaciÃ³nÂ PrecioÂ conÂ DescuentoÂ vsÂ Rating:Â {corr_discount:.3f}")
print(f"Â -Â CorrelaciÃ³nÂ PrecioÂ RealÂ vsÂ Rating:Â {corr_actual:.3f}")
```

InterpretaciÃ³n de Resultados
Los valores de correlaciÃ³n sonÂ positivos pero muy bajos, cercanos a 0.1.
Esto significa queÂ no existe una relaciÃ³n lineal fuerteÂ entre el precio de un producto (ni con descuento ni real) y su calificaciÃ³n promedio.
Los scatter plots muestran que los ratings se concentran entre 3.5 y 5, independientemente del rango de precios, lo cual refuerza la idea de que el precio no es un determinante del rating.
En comercio electrÃ³nico, esto sugiere que las calificaciones de los productos dependen mÃ¡s de laÂ calidad percibida, experiencia del usuario y reputaciÃ³n de la marca, que del precio en sÃ­.
Respuesta a la Pregunta de Negocio
No se observa una relaciÃ³n significativa entre el precio de un producto y su calificaciÃ³n promedio.
Tanto los productos de bajo precio como los de alto precio tienden a recibir calificaciones altas (por encima de 4 en promedio), indicando que el precio no es un factor determinante en la satisfacciÃ³n del cliente reflejada en las reseÃ±as.

top 10 de los productos mas populares

codigo:
```python
#Â IdentificarÂ losÂ productosÂ mÃ¡sÂ popularesÂ ordenandoÂ porÂ rating_count
#Â Seleccionaremos,Â porÂ ejemplo,Â losÂ 10Â productosÂ conÂ mayorÂ rating_count
productos_mas_popularesÂ =Â tabla_union.sort_values(by='rating_count',Â ascending=False).head(10)

print("ğŸ“ŠÂ LosÂ 10Â productosÂ mÃ¡sÂ popularesÂ (basadoÂ enÂ RatingÂ Count):")

#Â SeleccionarÂ lasÂ columnasÂ relevantesÂ paraÂ mostrar:Â nombre,Â rating_countÂ yÂ rating
columnas_mostrarÂ =Â ['product_name',Â 'rating_count',Â 'rating']

#Â AsegurarseÂ deÂ queÂ lasÂ columnasÂ existenÂ antesÂ deÂ mostrarlas
columnas_existentesÂ =Â [colÂ forÂ colÂ inÂ columnas_mostrarÂ ifÂ colÂ inÂ productos_mas_populares.columns]

ifÂ columnas_existentes:
Â Â Â Â display(productos_mas_populares[columnas_existentes])
else:
Â Â Â Â print("âš ï¸Â NoÂ seÂ pudieronÂ encontrarÂ lasÂ columnasÂ relevantesÂ paraÂ mostrar.")
```

codigo:
```python
importÂ matplotlib.pyplotÂ asÂ plt
importÂ seabornÂ asÂ sns

#Â AsegurarseÂ deÂ queÂ elÂ DataFrameÂ deÂ productos_mas_popularesÂ existe
ifÂ 'productos_mas_populares'Â inÂ globals()Â andÂ isinstance(globals()['productos_mas_populares'],Â pd.DataFrame):
Â Â Â Â print("ğŸ“ŠÂ GrÃ¡ficoÂ deÂ RatingÂ deÂ losÂ 10Â ProductosÂ MÃ¡sÂ Populares:")

Â Â Â Â plt.figure(figsize=(12,Â 7))Â #Â AjustarÂ tamaÃ±oÂ paraÂ mejorÂ visualizaciÃ³nÂ deÂ nombres
Â Â Â Â #Â OrdenarÂ porÂ rating_countÂ paraÂ queÂ elÂ grÃ¡ficoÂ reflejeÂ elÂ ordenÂ deÂ popularidad
Â Â Â Â productos_mas_populares_sortedÂ =Â productos_mas_populares.sort_values(by='rating_count',Â ascending=False)
Â Â Â Â sns.barplot(x='product_name',Â y='rating',Â data=productos_mas_populares_sorted,Â palette='viridis')

Â Â Â Â plt.title('RatingÂ PromedioÂ deÂ losÂ 10Â ProductosÂ MÃ¡sÂ PopularesÂ (porÂ ConteoÂ deÂ ReseÃ±as)')
Â Â Â Â plt.xlabel('Producto')
Â Â Â Â plt.ylabel('RatingÂ Promedio')
Â Â Â Â plt.ylim(0,Â 5)Â #Â EscalaÂ deÂ rating
Â Â Â Â plt.xticks(rotation=90,Â ha='right')Â #Â RotarÂ nombresÂ deÂ productosÂ paraÂ queÂ noÂ seÂ solapen
Â Â Â Â plt.tight_layout()Â #Â AjustarÂ elÂ diseÃ±o
Â Â Â Â plt.show()

else:
Â Â Â Â print("âš ï¸Â ElÂ DataFrameÂ 'productos_mas_populares'Â noÂ seÂ encontrÃ³.Â PorÂ favor,Â identificaÂ losÂ productosÂ mÃ¡sÂ popularesÂ primero.")
```

Informe Detallado sobre el AnÃ¡lisis de Datos de Productos y ReseÃ±as de Amazon
IntroducciÃ³n
Este informe presenta un anÃ¡lisis exploratorio detallado de un conjunto de datos de productos y reseÃ±as de la plataforma Amazon. El objetivo principal es comprender las caracterÃ­sticas de los productos y las reseÃ±as, identificar patrones clave y responder a preguntas de negocio relevantes, como la relaciÃ³n entre descuentos, precios y calificaciones de los productos, asÃ­ como la identificaciÃ³n de los productos mÃ¡s populares y su percepciÃ³n.
MetodologÃ­a
El anÃ¡lisis se llevÃ³ a cabo siguiendo una serie de pasos clave:
Carga y ExploraciÃ³n Inicial de los Datos:Â Se cargaron los datos de productos y reseÃ±as en DataFrames de pandas y se realizÃ³ una exploraciÃ³n inicial para entender su estructura, columnas y tipos de datos.
Limpieza de Datos:Â Se abordÃ³ la calidad de los datos mediante:
IdentificaciÃ³n y manejo de valores nulos.
ConversiÃ³n de columnas numÃ©ricas (precios, porcentaje de descuento, rating, rating_count) a tipos de datos apropiados, eliminando caracteres no numÃ©ricos.
IdentificaciÃ³n y anÃ¡lisis de registros duplicados en las tablas originales y la tabla fusionada.
IdentificaciÃ³n de valores fuera de rango en el porcentaje de descuento.
IdentificaciÃ³n de posibles outliers en las variables numÃ©ricas utilizando Z-Score e IQR.
FusiÃ³n de Tablas:Â Se combinÃ³ la informaciÃ³n de productos y reseÃ±as en una Ãºnica tabla (tabla_union) utilizando la columnaÂ product_idÂ como clave comÃºn.
AnÃ¡lisis Descriptivo Univariado:Â Se calcularon y analizaron medidas de tendencia central (media, moda, mediana) y de dispersiÃ³n (varianza, desviaciÃ³n estÃ¡ndar, rango intercuartÃ­lico) para las variables numÃ©ricas clave. Se visualizaron las distribuciones de estas variables mediante histogramas y grÃ¡ficos de densidad.
AnÃ¡lisis de CorrelaciÃ³n:Â Se calculÃ³ y visualizÃ³ la matriz de correlaciÃ³n de Pearson para entender las relaciones lineales entre las variables numÃ©ricas.
AnÃ¡lisis de Preguntas de Negocio EspecÃ­ficas:Â Se realizaron anÃ¡lisis dirigidos para responder a las preguntas planteadas:
Â¿Los productos con mayores descuentos tienen mejores calificaciones? (AnÃ¡lisis agrupado por rangos de descuento).
Â¿Existe relaciÃ³n entre el precio de un producto y su rating promedio? (AnÃ¡lisis de correlaciÃ³n y visualizaciÃ³n con scatter plots).
Â¿CuÃ¡les son los productos mÃ¡s populares y cÃ³mo se perciben? (IdentificaciÃ³n por conteo de reseÃ±as y anÃ¡lisis de ratings).
Resultados
Resumen de Limpieza de Datos
Durante la etapa de limpieza, se realizaron las siguientes acciones relevantes:
Se identificaron y manejaron valores nulos en columnas comoÂ about_product,Â img_linkÂ yÂ product_link.
Se convirtieron columnas comoÂ discounted_price,Â actual_price,Â discount_percentage,Â ratingÂ yÂ rating_countÂ a tipos numÃ©ricos, eliminando sÃ­mbolos monetarios, comas y porcentajes.
Se identificaron registros duplicados basados enÂ product_idÂ en la tabla de productos y se decidiÃ³ mantenerlos por el momento tras analizar que probablemente representen variaciones o listados diferentes.
Se identificaron registros duplicados en la tabla fusionada basados en combinaciones de columnas (nombre, descripciÃ³n, id de producto) y se confirmÃ³ que la mayorÃ­a representan reseÃ±as Ãºnicas para productos.
No se encontraron valores fuera del rango esperado (0-100) en la columnaÂ discount_percentage.
Se identificaron outliers en variables numÃ©ricas, especialmente enÂ rating_countÂ y precios, utilizando mÃ©todos Z-Score e IQR, y se decidiÃ³ mantenerlos inicialmente.
EstadÃ­sticas Descriptivas de Variables NumÃ©ricas
Las medidas de tendencia central y dispersiÃ³n para las variables numÃ©ricas clave son las siguientes:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ laÂ tablaÂ deÂ mÃ©tricasÂ descriptivas
columnas_numericas_descÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']
metricas_numericas_descÂ =Â {}
forÂ colÂ inÂ columnas_numericas_desc:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â mean_valÂ =Â tabla_union[col].mean()
Â Â Â Â Â Â Â Â median_valÂ =Â tabla_union[col].median()
Â Â Â Â Â Â Â Â mode_valÂ =Â tabla_union[col].mode().tolist()Â ifÂ notÂ tabla_union[col].mode().emptyÂ elseÂ None
Â Â Â Â Â Â Â Â std_valÂ =Â tabla_union[col].std()
Â Â Â Â Â Â Â Â metricas_numericas_desc[col]Â =Â {
Â Â Â Â Â Â Â Â Â Â Â Â 'Media':Â mean_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'Mediana':Â median_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'Moda':Â mode_val,
Â Â Â Â Â Â Â Â Â Â Â Â 'DesviaciÃ³nÂ EstÃ¡ndar':Â std_val
Â Â Â Â Â Â Â Â }
Â Â Â Â else:
Â Â Â Â Â Â Â Â metricas_numericas_desc[col]Â =Â {'Media':Â None,Â 'Mediana':Â None,Â 'Moda':Â None,Â 'DesviaciÃ³nÂ EstÃ¡ndar':Â None}Â #Â HandleÂ missingÂ columns

df_metricas_descÂ =Â pd.DataFrame(metricas_numericas_desc).T
display(df_metricas_desc)
```

Distribuciones de Variables NumÃ©ricas
Las distribuciones de las variables numÃ©ricas se visualizaron con histogramas y grÃ¡ficos de densidad, revelando lo siguiente:
discounted_priceÂ yÂ actual_price:Â Ambas presentan una distribuciÃ³n marcadamenteÂ sesgada a la derecha (positivamente), con la mayorÃ­a de los precios concentrados en valores bajos y una cola larga hacia precios mÃ¡s altos.
discount_percentage:Â Muestra una distribuciÃ³nÂ aproximadamente simÃ©trica, con una concentraciÃ³n alrededor de la moda del 50%.
rating:Â Tiene una distribuciÃ³n fuertementeÂ sesgada a la izquierda (negativamente), con la gran mayorÃ­a de las calificaciones concentradas en los valores mÃ¡s altos (4-5).
rating_count:Â Exhibe una distribuciÃ³nÂ altamente sesgada a la derecha (positivamente), con un pico masivo en valores bajos y una cola extremadamente larga hacia valores muy altos, indicando la presencia de productos con un nÃºmero de reseÃ±as excepcionalmente alto.
A continuaciÃ³n se muestran los histogramas correspondientes:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ losÂ histogramas
columnas_numericas_histÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']
sns.set_style("whitegrid")
forÂ colÂ inÂ columnas_numericas_hist:
Â Â Â Â ifÂ colÂ inÂ tabla_union.columns:
Â Â Â Â Â Â Â Â plt.figure(figsize=(10,Â 6))
Â Â Â Â Â Â Â Â sns.histplot(data=tabla_union,Â x=col,Â kde=True)
Â Â Â Â Â Â Â Â plt.title(f'DistribuciÃ³nÂ deÂ {col}')
Â Â Â Â Â Â Â Â plt.xlabel(col)
Â Â Â Â Â Â Â Â plt.ylabel('Frecuencia')
Â Â Â Â Â Â Â Â plt.show()
Â Â Â Â else:
Â Â Â Â Â Â Â Â print(f"âš ï¸Â Advertencia:Â LaÂ columnaÂ '{col}'Â noÂ seÂ encontrÃ³Â paraÂ elÂ histograma.")
```

AnÃ¡lisis de CorrelaciÃ³n
La matriz de correlaciÃ³n de Pearson entre las variables numÃ©ricas es la siguiente:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ laÂ matrizÂ deÂ correlaciÃ³n
columnas_numericas_corrÂ =Â ['discounted_price',Â 'actual_price',Â 'discount_percentage',Â 'rating',Â 'rating_count']
columnas_existentes_corrÂ =Â [colÂ forÂ colÂ inÂ columnas_numericas_corrÂ ifÂ colÂ inÂ tabla_union.columns]
ifÂ len(columnas_existentes_corr)Â >Â 1:
Â Â Â Â correlacion_pearson_reportÂ =Â tabla_union[columnas_existentes_corr].corr(method='pearson')
Â Â Â Â display(correlacion_pearson_report)
else:
Â Â Â Â print("âš ï¸Â NoÂ hayÂ suficientesÂ columnasÂ numÃ©ricasÂ paraÂ laÂ matrizÂ deÂ correlaciÃ³nÂ enÂ elÂ informe.")
```

El mapa de calor de correlaciÃ³n visualiza estas relaciones:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ elÂ mapaÂ deÂ calorÂ deÂ correlaciÃ³n
ifÂ 'correlacion_pearson_report'Â inÂ globals()Â andÂ isinstance(globals()['correlacion_pearson_report'],Â pd.DataFrame):
Â Â Â Â plt.figure(figsize=(10,Â 8))
Â Â Â Â sns.heatmap(correlacion_pearson_report,Â annot=True,Â cmap='coolwarm',Â fmt=".2f",Â linewidths=.5)
Â Â Â Â plt.title('MapaÂ deÂ CalorÂ deÂ laÂ MatrizÂ deÂ CorrelaciÃ³nÂ deÂ Pearson')
Â Â Â Â plt.show()
else:
Â Â Â Â Â print("âš ï¸Â LaÂ matrizÂ deÂ correlaciÃ³nÂ noÂ seÂ encontrÃ³Â paraÂ elÂ mapaÂ deÂ calorÂ enÂ elÂ informe.")
```

Los hallazgos clave de la correlaciÃ³n son: una alta correlaciÃ³n positiva entreÂ discounted_priceÂ yÂ actual_priceÂ (0.96), y correlaciones lineales dÃ©biles o muy dÃ©biles entre el resto de pares de variables, incluyendo las relaciones entre precios/descuento y rating/conteo de reseÃ±as.
AnÃ¡lisis de Preguntas de Negocio
Â¿Los productos con mayores descuentos tienen mejores calificaciones?
Para responder a esto, analizamos el rating promedio por rangos de porcentaje de descuento definidos por cuartiles.

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ laÂ tablaÂ deÂ mÃ©tricasÂ porÂ rangoÂ deÂ descuento
ifÂ 'discount_range_metrics'Â inÂ globals()Â andÂ isinstance(globals()['discount_range_metrics'],Â pd.DataFrame):
Â Â Â Â print("ğŸ“ŠÂ RatingÂ PromedioÂ porÂ RangoÂ deÂ PorcentajeÂ deÂ Descuento:")
Â Â Â Â display(discount_range_metrics[['avg_discount_percentage',Â 'avg_rating']])
else:
Â Â Â Â print("âš ï¸Â LaÂ tablaÂ 'discount_range_metrics'Â noÂ seÂ encontrÃ³Â paraÂ elÂ informe.")
```

La visualizaciÃ³n del rating promedio por rango de descuento es la siguiente:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ elÂ grÃ¡ficoÂ deÂ barrasÂ deÂ ratingÂ promedioÂ porÂ rangoÂ deÂ descuento
ifÂ 'discount_range_metrics'Â inÂ globals()Â andÂ isinstance(globals()['discount_range_metrics'],Â pd.DataFrame):
Â Â Â Â plt.figure(figsize=(10,Â 6))
Â Â Â Â sns.barplot(x=discount_range_metrics.index,Â y='avg_rating',Â data=discount_range_metrics,Â palette='viridis')
Â Â Â Â plt.title('RatingÂ PromedioÂ porÂ RangoÂ deÂ PorcentajeÂ deÂ Descuento')
Â Â Â Â plt.xlabel('RangoÂ deÂ PorcentajeÂ deÂ Descuento')
Â Â Â Â plt.ylabel('RatingÂ Promedio')
Â Â Â Â plt.ylim(0,Â 5)
Â Â Â Â plt.xticks(rotation=0)
Â Â Â Â plt.tight_layout()
Â Â Â Â plt.show()
else:
Â Â Â Â print("âš ï¸Â LaÂ tablaÂ 'discount_range_metrics'Â noÂ seÂ encontrÃ³Â paraÂ elÂ grÃ¡ficoÂ enÂ elÂ informe.")
```

Respuesta:Â Basado en el anÃ¡lisis y el grÃ¡fico, los productos con mayores porcentajes de descuentoÂ no tienen mejores calificaciones promedio. Se observa una ligera tendencia a que los rangos con menores descuentos tengan ratings promedio marginalmente mÃ¡s altos.
Â¿Existe relaciÃ³n entre el precio de un producto y su rating promedio?
Analizamos esta relaciÃ³n mediante grÃ¡ficos de dispersiÃ³n.

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ losÂ scatterÂ plotsÂ deÂ precioÂ vsÂ rating
sns.set_style("whitegrid")
plt.figure(figsize=(10,Â 6))
sns.scatterplot(data=tabla_union,Â x='discounted_price',Â y='rating',Â alpha=0.6)
plt.title('RelaciÃ³nÂ entreÂ PrecioÂ conÂ DescuentoÂ yÂ RatingÂ Promedio')
plt.xlabel('PrecioÂ conÂ Descuento')
plt.ylabel('RatingÂ Promedio')
plt.ylim(0,Â 5.1)
plt.grid(True)
plt.show()

plt.figure(figsize=(10,Â 6))
sns.scatterplot(data=tabla_union,Â x='actual_price',Â y='rating',Â alpha=0.6)
plt.title('RelaciÃ³nÂ entreÂ PrecioÂ RealÂ yÂ RatingÂ Promedio')
plt.xlabel('PrecioÂ Real')
plt.ylabel('RatingÂ Promedio')
plt.ylim(0,Â 5.1)
plt.grid(True)
plt.show()
```

Respuesta:Â Los grÃ¡ficos de dispersiÃ³n confirman la debilidad de la correlaciÃ³n lineal previamente calculada.Â No parece haber una relaciÃ³n lineal fuerte o claraÂ entre el precio de un producto y su rating promedio en este conjunto de datos. Los ratings altos se observan en un amplio rango de precios.
Â¿CuÃ¡les son los productos mÃ¡s populares y cÃ³mo se perciben?
Identificamos los productos mÃ¡s populares basÃ¡ndonos en elÂ rating_countÂ (nÃºmero de reseÃ±as).

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ laÂ tablaÂ deÂ losÂ 10Â productosÂ mÃ¡sÂ populares
productos_mas_populares_reportÂ =Â tabla_union.sort_values(by='rating_count',Â ascending=False).head(10)
columnas_mostrar_reportÂ =Â ['product_name',Â 'rating_count',Â 'rating']
columnas_existentes_reportÂ =Â [colÂ forÂ colÂ inÂ columnas_mostrar_reportÂ ifÂ colÂ inÂ productos_mas_populares_report.columns]
ifÂ columnas_existentes_report:
Â Â Â Â print("ğŸ“ŠÂ LosÂ 10Â productosÂ mÃ¡sÂ popularesÂ (basadoÂ enÂ RatingÂ Count):")
Â Â Â Â display(productos_mas_populares_report[columnas_existentes_report])
else:
Â Â Â Â print("âš ï¸Â NoÂ seÂ pudieronÂ encontrarÂ lasÂ columnasÂ relevantesÂ paraÂ mostrarÂ losÂ productosÂ popularesÂ enÂ elÂ informe.")
```

La percepciÃ³n de estos productos populares se visualiza a travÃ©s de sus ratings promedio:

codigo:
```python
#Â RegenerarÂ yÂ mostrarÂ elÂ grÃ¡ficoÂ deÂ barrasÂ deÂ ratingÂ deÂ losÂ productosÂ mÃ¡sÂ populares
ifÂ 'productos_mas_populares_report'Â inÂ globals()Â andÂ isinstance(globals()['productos_mas_populares_report'],Â pd.DataFrame)Â andÂ notÂ productos_mas_populares_report.empty:
Â Â Â Â plt.figure(figsize=(12,Â 7))
Â Â Â Â productos_mas_populares_sorted_reportÂ =Â productos_mas_populares_report.sort_values(by='rating_count',Â ascending=False)
Â Â Â Â sns.barplot(x='product_name',Â y='rating',Â data=productos_mas_populares_sorted_report,Â palette='viridis')
Â Â Â Â plt.title('RatingÂ PromedioÂ deÂ losÂ 10Â ProductosÂ MÃ¡sÂ PopularesÂ (porÂ ConteoÂ deÂ ReseÃ±as)')
Â Â Â Â plt.xlabel('Producto')
Â Â Â Â plt.ylabel('RatingÂ Promedio')
Â Â Â Â plt.ylim(0,Â 5)
Â Â Â Â plt.xticks(rotation=90,Â ha='right')
Â Â Â Â plt.tight_layout()
Â Â Â Â plt.show()
else:
Â Â Â Â print("âš ï¸Â NoÂ seÂ pudoÂ generarÂ elÂ grÃ¡ficoÂ deÂ productosÂ popularesÂ paraÂ elÂ informe.")
```

Respuesta:Â Los productos mÃ¡s populares (generalmente electrÃ³nicos y accesorios de uso masivo) tienen una percepciÃ³nÂ muy positiva, con la gran mayorÃ­a presentando ratings promedio altos (4.1 o superior), como se evidencia en la tabla y el grÃ¡fico.
Conclusiones
Este anÃ¡lisis exploratorio ha revelado varias caracterÃ­sticas importantes del conjunto de datos:
Distribuciones AsimÃ©tricas:Â Las variables de precio yÂ rating_countÂ exhiben una fuerte asimetrÃ­a positiva, mientras queÂ ratingÂ estÃ¡ sesgado negativamente, reflejando la diversidad de precios, la alta popularidad concentrada en pocos productos y la tendencia general a ratings altos.
Ratings Generalmente Altos:Â La mayorÃ­a de los productos en el dataset reciben calificaciones promedio altas (superiores a 4.0).
DÃ©bil RelaciÃ³n Lineal con Precio y Descuento:Â No se encontrÃ³ una relaciÃ³n lineal fuerte entre el precio/porcentaje de descuento y el rating promedio. Los productos con mayores descuentos no tienen mejores calificaciones en promedio; de hecho, se observÃ³ una ligera tendencia inversa.
Productos Populares Bien Percibidos:Â Los productos con el mayor nÃºmero de reseÃ±as (mÃ¡s populares) tienden a tener ratings promedio altos, sugiriendo una percepciÃ³n generalmente positiva entre un gran nÃºmero de usuarios.
Duplicados y Nulos:Â Se identificaron y manejaron nulos y diversos tipos de duplicados, aunque algunos (como productos con el mismo nombre pero diferente ID) se mantuvieron para anÃ¡lisis posteriores.
Aspectos y Hallazgos MÃ¡s Relevantes para el Informe Final:
La distribuciÃ³n altamente sesgada deÂ rating_countÂ y su implicaciÃ³n en la representatividad del rating.
La tendencia general a ratings altos.
La falta de una relaciÃ³n lineal fuerte entre precio/descuento y rating.
La percepciÃ³n positiva de los productos mÃ¡s populares.
La identificaciÃ³n y manejo de los principales problemas de calidad de datos (nulos, duplicados, formato numÃ©rico).
Recomendaciones
Basado en este anÃ¡lisis, se sugieren los siguientes prÃ³ximos pasos:
Explorar Relaciones No Lineales:Â Investigar si existen relaciones no lineales entre precio/descuento y rating que no fueron capturadas por la correlaciÃ³n de Pearson.
AnÃ¡lisis por SubcategorÃ­as:Â Realizar anÃ¡lisis similares (mÃ©tricas, distribuciones, relaciones) dentro de subcategorÃ­as de productos mÃ¡s especÃ­ficas para identificar patrones que podrÃ­an estar ocultos en las categorÃ­as amplias.
AnÃ¡lisis de Texto:Â Si es relevante, realizar anÃ¡lisis de sentimiento o extracciÃ³n de temas en los tÃ­tulos y contenidos de las reseÃ±as para comprender mejor las razones detrÃ¡s de los ratings altos o bajos.
Considerar Transformaciones para Modelado:Â Si el objetivo es construir modelos predictivos, evaluar la necesidad de transformar variables altamente asimÃ©tricas comoÂ rating_countÂ para cumplir con los supuestos de ciertos algoritmos.
Investigar Duplicados Restantes:Â Si es crucial para el anÃ¡lisis, profundizar en la causa de los productos con el mismo nombre pero diferente ID.
Este informe resume los hallazgos clave y proporciona una base sÃ³lida para anÃ¡lisis futuros y la toma de decisiones basada en datos.
